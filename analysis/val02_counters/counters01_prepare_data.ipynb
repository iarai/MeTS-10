{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "a6c21581",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import glob\n",
    "import json\n",
    "import locale\n",
    "import os\n",
    "import re\n",
    "import tempfile\n",
    "import xml.etree.ElementTree as ET\n",
    "import zipfile\n",
    "from calendar import monthrange\n",
    "from datetime import datetime, timedelta\n",
    "from io import TextIOWrapper\n",
    "from math import floor\n",
    "from pathlib import Path\n",
    "\n",
    "import boto3\n",
    "import geojson\n",
    "import geopandas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyproj\n",
    "import requests\n",
    "from shapely.geometry import Point\n",
    "from shapely.ops import transform\n",
    "\n",
    "# DATA_PATH expects a working structure with mets10 data generated and city subfolders\n",
    "# ├── loop_counters\n",
    "# │   ├── berlin\n",
    "# │   │   ├── downloads\n",
    "# │   │   └── speed\n",
    "# │   ├── london\n",
    "# │   │   ├── downloads\n",
    "# │   │   └── speed\n",
    "# │   └── madrid\n",
    "# │       ├── all\n",
    "# │       └── downloads\n",
    "# └── release20221026_residential_unclassified\n",
    "#     ├── 2021\n",
    "#     │   ├── road_graph\n",
    "#     │   │   └── berlin\n",
    "#     │   └── speed_classes\n",
    "#     │       └── berlin\n",
    "#     └── 2022\n",
    "#         ├── road_graph\n",
    "#         │   ├── london\n",
    "#         │   └── madrid\n",
    "#         └── speed_classes\n",
    "#             ├── london\n",
    "#             └── madrid\n",
    "DATA_PATH = Path('/private/data/mets10') \n",
    "BERLIN_PATH = DATA_PATH / 'loop_counters' / 'berlin'\n",
    "LONDON_PATH = DATA_PATH / 'loop_counters' / 'london'\n",
    "MADRID_PATH = DATA_PATH / 'loop_counters' / 'madrid'\n",
    "MELBOURNE_PATH = DATA_PATH / 'loop_counters' / 'melbourne'  # not used for MeTS-10 validations (no time overlap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84b1d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gdf(df, id_field='id', bbox=None):\n",
    "    df = df.copy()\n",
    "    df['id'] = df[id_field].astype(str)\n",
    "    if 'lat' not  in df.columns:\n",
    "        df['lon'] = df.geometry.x\n",
    "        df['lat'] = df.geometry.y\n",
    "    if 'heading' not in df.columns:\n",
    "        df['heading'] = -1\n",
    "    df = df[['id', 'lat', 'lon', 'heading']]\n",
    "    gdf = geopandas.GeoDataFrame(\n",
    "        df, geometry=geopandas.points_from_xy(df.lon, df.lat))\n",
    "    if bbox:\n",
    "        ymin, ymax, xmin, xmax = tuple([v/100000 for v in bbox])\n",
    "        gdf = gdf.cx[xmin:xmax, ymin:ymax]\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e95f14",
   "metadata": {},
   "source": [
    "# Berlin\n",
    "\n",
    "Raw loop counter data was downloaded from\n",
    "https://api.viz.berlin.de/daten/verkehrsdetektion/teu_standorte.json and https://api.viz.berlin.de/daten/verkehrsdetektion?path=2020%2FDetektoren+%28einzelne+Fahrspur%29%2F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f44ae3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detname</th>\n",
       "      <th>detid_15</th>\n",
       "      <th>heading</th>\n",
       "      <th>lane</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>100101010000167</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TE001_Det_HF2</td>\n",
       "      <td>100101010000268</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TE002_Det_HF1</td>\n",
       "      <td>100101010000369</td>\n",
       "      <td>45</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192747</td>\n",
       "      <td>52.433813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TE002_Det_HF2</td>\n",
       "      <td>100101010000470</td>\n",
       "      <td>45</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.192747</td>\n",
       "      <td>52.433813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TE004_Det_HF1</td>\n",
       "      <td>100101010000874</td>\n",
       "      <td>180</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.261301</td>\n",
       "      <td>52.436642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>TE583_Det_HF2</td>\n",
       "      <td>100101010097975</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.384196</td>\n",
       "      <td>52.457440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>TE592_Det_HF1</td>\n",
       "      <td>100101010099692</td>\n",
       "      <td>180</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.301719</td>\n",
       "      <td>52.509232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>TE592_Det_HF2</td>\n",
       "      <td>100101010099793</td>\n",
       "      <td>180</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.301719</td>\n",
       "      <td>52.509232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>TE593_Det_HF1</td>\n",
       "      <td>100101010099894</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>100101010099995</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>548 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           detname         detid_15  heading    lane        lon        lat\n",
       "0    TE001_Det_HF1  100101010000167      225    HF_R  13.192578  52.433868\n",
       "1    TE001_Det_HF2  100101010000268      225  HF_2vR  13.192578  52.433868\n",
       "2    TE002_Det_HF1  100101010000369       45    HF_R  13.192747  52.433813\n",
       "3    TE002_Det_HF2  100101010000470       45  HF_2vR  13.192747  52.433813\n",
       "4    TE004_Det_HF1  100101010000874      180    HF_R  13.261301  52.436642\n",
       "..             ...              ...      ...     ...        ...        ...\n",
       "543  TE583_Det_HF2  100101010097975        0  HF_2vR  13.384196  52.457440\n",
       "544  TE592_Det_HF1  100101010099692      180    HF_R  13.301719  52.509232\n",
       "545  TE592_Det_HF2  100101010099793      180  HF_2vR  13.301719  52.509232\n",
       "546  TE593_Det_HF1  100101010099894        0    HF_R  13.302183  52.508531\n",
       "547  TE593_Det_HF2  100101010099995        0  HF_2vR  13.302183  52.508531\n",
       "\n",
       "[548 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_locations_df = pd.read_excel(BERLIN_PATH / 'downloads' / 'Stammdaten_Verkehrsdetektion_2022_07_20.xlsx')\n",
    "berlin_locations_df = berlin_locations_df[[\n",
    "    'DET_NAME_NEU', 'DET_ID15', 'RICHTUNG', 'SPUR', 'LÄNGE (WGS84)', 'BREITE (WGS84)']]\n",
    "berlin_locations_df = berlin_locations_df.rename(columns={\n",
    "    'DET_NAME_NEU': 'detname', 'DET_ID15': 'detid_15', 'LÄNGE (WGS84)': 'lon', 'BREITE (WGS84)': 'lat',\n",
    "    'SPUR': 'lane', 'RICHTUNG': 'heading'})\n",
    "berlin_locations_df = berlin_locations_df.replace({'heading': {\n",
    "    'Nord': 0, 'Nordost': 45, 'Ost': 90, 'Südost': 135,\n",
    "    'Süd': 180, 'Südwest': 225, 'West': 270, 'Nordwest': 315\n",
    "}})\n",
    "berlin_locations_df = berlin_locations_df.groupby(by=['detname', 'detid_15', 'heading', 'lane', 'lon', 'lat']).count()\n",
    "berlin_locations_df = berlin_locations_df.reset_index()\n",
    "berlin_locations_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd5da0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>detname</th>\n",
       "      <th>detid_15</th>\n",
       "      <th>heading</th>\n",
       "      <th>lane</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [detname, detid_15, heading, lane, lon, lat]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "berlin_locations_df[berlin_locations_df['detid_15'].duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "097e98b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the counter locations to geojson\n",
    "get_gdf(berlin_locations_df, 'detid_15').to_file(BERLIN_PATH / 'counter_locations.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b92a21cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 373739 rows with 546 unique counters\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>tag</th>\n",
       "      <th>stunde</th>\n",
       "      <th>qualitaet</th>\n",
       "      <th>q_kfz_det_hr</th>\n",
       "      <th>v_kfz_det_hr</th>\n",
       "      <th>q_pkw_det_hr</th>\n",
       "      <th>v_pkw_det_hr</th>\n",
       "      <th>q_lkw_det_hr</th>\n",
       "      <th>v_lkw_det_hr</th>\n",
       "      <th>name</th>\n",
       "      <th>heading</th>\n",
       "      <th>lane</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>time_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100101010000167</td>\n",
       "      <td>01.06.2019</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>227</td>\n",
       "      <td>82.8</td>\n",
       "      <td>207</td>\n",
       "      <td>83.9</td>\n",
       "      <td>20</td>\n",
       "      <td>71.6</td>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "      <td>2019-06-01 00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100101010000167</td>\n",
       "      <td>01.06.2019</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131</td>\n",
       "      <td>78.4</td>\n",
       "      <td>115</td>\n",
       "      <td>80.5</td>\n",
       "      <td>16</td>\n",
       "      <td>63.7</td>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "      <td>2019-06-01 01:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100101010000167</td>\n",
       "      <td>01.06.2019</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>94</td>\n",
       "      <td>77.0</td>\n",
       "      <td>74</td>\n",
       "      <td>80.6</td>\n",
       "      <td>20</td>\n",
       "      <td>63.3</td>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "      <td>2019-06-01 02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100101010000167</td>\n",
       "      <td>01.06.2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83</td>\n",
       "      <td>76.4</td>\n",
       "      <td>68</td>\n",
       "      <td>76.2</td>\n",
       "      <td>15</td>\n",
       "      <td>77.3</td>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "      <td>2019-06-01 03:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100101010000167</td>\n",
       "      <td>01.06.2019</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131</td>\n",
       "      <td>76.9</td>\n",
       "      <td>118</td>\n",
       "      <td>78.8</td>\n",
       "      <td>13</td>\n",
       "      <td>59.9</td>\n",
       "      <td>TE001_Det_HF1</td>\n",
       "      <td>225</td>\n",
       "      <td>HF_R</td>\n",
       "      <td>13.192578</td>\n",
       "      <td>52.433868</td>\n",
       "      <td>2019-06-01 04:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373734</th>\n",
       "      <td>100101010099995</td>\n",
       "      <td>30.06.2019</td>\n",
       "      <td>19</td>\n",
       "      <td>1.0</td>\n",
       "      <td>191</td>\n",
       "      <td>43.4</td>\n",
       "      <td>189</td>\n",
       "      <td>43.4</td>\n",
       "      <td>2</td>\n",
       "      <td>42.0</td>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "      <td>2019-06-30 19:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373735</th>\n",
       "      <td>100101010099995</td>\n",
       "      <td>30.06.2019</td>\n",
       "      <td>20</td>\n",
       "      <td>1.0</td>\n",
       "      <td>219</td>\n",
       "      <td>42.2</td>\n",
       "      <td>216</td>\n",
       "      <td>42.4</td>\n",
       "      <td>3</td>\n",
       "      <td>27.3</td>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "      <td>2019-06-30 20:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373736</th>\n",
       "      <td>100101010099995</td>\n",
       "      <td>30.06.2019</td>\n",
       "      <td>21</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265</td>\n",
       "      <td>39.6</td>\n",
       "      <td>257</td>\n",
       "      <td>39.9</td>\n",
       "      <td>8</td>\n",
       "      <td>29.5</td>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "      <td>2019-06-30 21:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373737</th>\n",
       "      <td>100101010099995</td>\n",
       "      <td>30.06.2019</td>\n",
       "      <td>22</td>\n",
       "      <td>1.0</td>\n",
       "      <td>158</td>\n",
       "      <td>43.2</td>\n",
       "      <td>157</td>\n",
       "      <td>43.3</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "      <td>2019-06-30 22:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373738</th>\n",
       "      <td>100101010099995</td>\n",
       "      <td>30.06.2019</td>\n",
       "      <td>23</td>\n",
       "      <td>1.0</td>\n",
       "      <td>121</td>\n",
       "      <td>43.5</td>\n",
       "      <td>116</td>\n",
       "      <td>43.8</td>\n",
       "      <td>5</td>\n",
       "      <td>35.6</td>\n",
       "      <td>TE593_Det_HF2</td>\n",
       "      <td>0</td>\n",
       "      <td>HF_2vR</td>\n",
       "      <td>13.302183</td>\n",
       "      <td>52.508531</td>\n",
       "      <td>2019-06-30 23:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>373739 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id         tag  stunde  qualitaet  q_kfz_det_hr  \\\n",
       "0       100101010000167  01.06.2019       0        1.0           227   \n",
       "1       100101010000167  01.06.2019       1        1.0           131   \n",
       "2       100101010000167  01.06.2019       2        1.0            94   \n",
       "3       100101010000167  01.06.2019       3        1.0            83   \n",
       "4       100101010000167  01.06.2019       4        1.0           131   \n",
       "...                 ...         ...     ...        ...           ...   \n",
       "373734  100101010099995  30.06.2019      19        1.0           191   \n",
       "373735  100101010099995  30.06.2019      20        1.0           219   \n",
       "373736  100101010099995  30.06.2019      21        1.0           265   \n",
       "373737  100101010099995  30.06.2019      22        1.0           158   \n",
       "373738  100101010099995  30.06.2019      23        1.0           121   \n",
       "\n",
       "        v_kfz_det_hr  q_pkw_det_hr  v_pkw_det_hr  q_lkw_det_hr  v_lkw_det_hr  \\\n",
       "0               82.8           207          83.9            20          71.6   \n",
       "1               78.4           115          80.5            16          63.7   \n",
       "2               77.0            74          80.6            20          63.3   \n",
       "3               76.4            68          76.2            15          77.3   \n",
       "4               76.9           118          78.8            13          59.9   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "373734          43.4           189          43.4             2          42.0   \n",
       "373735          42.2           216          42.4             3          27.3   \n",
       "373736          39.6           257          39.9             8          29.5   \n",
       "373737          43.2           157          43.3             1          42.0   \n",
       "373738          43.5           116          43.8             5          35.6   \n",
       "\n",
       "                 name  heading    lane        lon        lat          time_bin  \n",
       "0       TE001_Det_HF1      225    HF_R  13.192578  52.433868  2019-06-01 00:00  \n",
       "1       TE001_Det_HF1      225    HF_R  13.192578  52.433868  2019-06-01 01:00  \n",
       "2       TE001_Det_HF1      225    HF_R  13.192578  52.433868  2019-06-01 02:00  \n",
       "3       TE001_Det_HF1      225    HF_R  13.192578  52.433868  2019-06-01 03:00  \n",
       "4       TE001_Det_HF1      225    HF_R  13.192578  52.433868  2019-06-01 04:00  \n",
       "...               ...      ...     ...        ...        ...               ...  \n",
       "373734  TE593_Det_HF2        0  HF_2vR  13.302183  52.508531  2019-06-30 19:00  \n",
       "373735  TE593_Det_HF2        0  HF_2vR  13.302183  52.508531  2019-06-30 20:00  \n",
       "373736  TE593_Det_HF2        0  HF_2vR  13.302183  52.508531  2019-06-30 21:00  \n",
       "373737  TE593_Det_HF2        0  HF_2vR  13.302183  52.508531  2019-06-30 22:00  \n",
       "373738  TE593_Det_HF2        0  HF_2vR  13.302183  52.508531  2019-06-30 23:00  \n",
       "\n",
       "[373739 rows x 16 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_counters_merged(year, month, locations_df):\n",
    "    df = pd.read_csv(BERLIN_PATH / 'downloads' / f'det_val_hr_{year:04d}_{month:02d}.csv.gz', sep=';',\n",
    "                     compression='gzip')\n",
    "    print(f'Loaded {len(df)} rows with {len(df[\"detid_15\"].unique())} unique counters')\n",
    "    df = df.merge(locations_df, on=['detid_15'], how='left')\n",
    "    df = df.rename(columns={'detid_15': 'id', 'detname': 'name'})\n",
    "    df['time_bin'] = [f'{d[6:]}-{d[3:5]}-{d[:2]} {h:02d}:00' for d, h in zip(df['tag'], df['stunde'])]\n",
    "    df.to_parquet(BERLIN_PATH / 'speed' / f'counters_{year:04d}-{month:02d}.parquet', compression=\"snappy\")\n",
    "    return df\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "# get_counters_merged(2021, 7, berlin_locations_df)\n",
    "get_counters_merged(2019, 6, berlin_locations_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5416262",
   "metadata": {},
   "source": [
    "# London\n",
    "\n",
    "Scraping counter data from the Highways England WebTRIS API https://webtris.highwaysengland.co.uk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1f19599",
   "metadata": {},
   "outputs": [],
   "source": [
    "WEBTRIS = 'https://webtris.highwaysengland.co.uk/api/v1'\n",
    "LONDON_BBOX = [5120500, 5170000, -36900, 6700]\n",
    "\n",
    "def save_json_rows(data, file_name):\n",
    "    if not data:\n",
    "        return\n",
    "    with open(LONDON_PATH / 'downloads' / f'{file_name}.json', 'w') as f:\n",
    "        for row in data:\n",
    "            json.dump(row, f)\n",
    "            f.write('\\n')\n",
    "\n",
    "def get_webtris_sites(bbox):\n",
    "    min_lat, max_lat, min_lon, max_lon = tuple(bbox)\n",
    "    url = f'{WEBTRIS}/sites'\n",
    "    req = requests.get(url)\n",
    "    req_json = req.json()\n",
    "    print(req_json['row_count'])\n",
    "    for site in req_json['sites']:\n",
    "        lat_bin = int(floor(site['Latitude'] * 1e3) / 1e3 * 1e5)\n",
    "        lon_bin = int(floor(site['Longitude'] * 1e3) / 1e3 * 1e5)\n",
    "        if lat_bin >= min_lat and lat_bin <= max_lat:\n",
    "            site['lat_bin'] = lat_bin\n",
    "            site['lon_bin'] = lon_bin\n",
    "            yield site\n",
    "\n",
    "def time_ceil(time, delta):\n",
    "    mod = (time - datetime(1970, 1, 1)) % delta\n",
    "    if mod:\n",
    "        return time + (delta - mod)\n",
    "    return time\n",
    "\n",
    "def time_bin_format(time):\n",
    "    return time.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def get_time_bins(datetime_str):\n",
    "    time_bins = datetime.strptime(datetime_str, '%Y-%m-%d %H:%M:%S')\n",
    "    time_bins = time_ceil(time_bins, timedelta(minutes=5))\n",
    "    return [\n",
    "        time_bin_format(time_bins-timedelta(minutes=10)),\n",
    "        time_bin_format(time_bins-timedelta(minutes=5)),\n",
    "        time_bin_format(time_bins)\n",
    "    ]\n",
    "\n",
    "def join_site_info(data, sites_dict):\n",
    "    for row in data:\n",
    "        site = sites_dict[row['Site Name']]\n",
    "        volume = row['Total Volume']\n",
    "        if volume:\n",
    "            volume = int(volume)\n",
    "        else:\n",
    "            volume = 0\n",
    "        speed = row['Avg mph']\n",
    "        if speed:\n",
    "            speed = float(speed)*1.60934\n",
    "        else:\n",
    "            speed = 0\n",
    "        time_bins = get_time_bins(f\"{row['Report Date'][:10]} {row['Time Period Ending']}\")\n",
    "        yield {\n",
    "            'id': int(site['Id']), 'name': row['Site Name'],\n",
    "            'lat_bin': site['lat_bin'], 'lon_bin': site['lon_bin'],\n",
    "            'lat': site['Latitude'], 'lon': site['Longitude'],\n",
    "            'time_bins': time_bins,\n",
    "            'volume': volume, 'speed': speed\n",
    "        }\n",
    "\n",
    "def get_chunk(id_chunk, date_from, date_to):\n",
    "    date_from = datetime.strptime(date_from, '%Y-%m-%d').strftime('%d%m%Y')\n",
    "    date_to = datetime.strptime(date_to, '%Y-%m-%d').strftime('%d%m%Y')\n",
    "    req_ids_urlenc = ','.join(id_chunk)\n",
    "    url = f'{WEBTRIS}/reports/{date_from}/to/{date_to}/Daily?sites={req_ids_urlenc}&page=1&page_size=10000'\n",
    "    while True:\n",
    "        print(url)\n",
    "        req = requests.get(url)\n",
    "        if req.status_code == 204:\n",
    "            return\n",
    "        req_json = req.json()\n",
    "        yield from req_json['Rows']\n",
    "        header = req_json['Header']\n",
    "        print(header)\n",
    "        if 'links' in header and len(header['links']) > 0 and header['links'][-1]['rel'] == 'nextPage':\n",
    "            url =  header['links'][-1]['href']\n",
    "            continue\n",
    "        else:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79383c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19355\n",
      "4256\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'Id': '1',\n",
       "  'Name': 'MIDAS site at M4/2295A2 priority 1 on link 105009001; GPS Ref: 502816;178156; Westbound',\n",
       "  'Description': 'M4/2295A2',\n",
       "  'Longitude': -0.520379557723297,\n",
       "  'Latitude': 51.4930115367112,\n",
       "  'Status': 'Inactive',\n",
       "  'lat_bin': 5149300,\n",
       "  'lon_bin': -52100},\n",
       " {'Id': '5',\n",
       "  'Name': 'MIDAS site at M25/5764B priority 1 on link 199056702; GPS Ref: 558308;188775; Anti-clockwise',\n",
       "  'Description': 'M25/5764B',\n",
       "  'Longitude': 0.283161593410359,\n",
       "  'Latitude': 51.5756168053165,\n",
       "  'Status': 'Active',\n",
       "  'lat_bin': 5157500,\n",
       "  'lon_bin': 28299}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "webtris_sites = list(get_webtris_sites(LONDON_BBOX))\n",
    "save_json_rows(webtris_sites, 'webtris_sites')\n",
    "print(len(webtris_sites))\n",
    "webtris_sites[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ee45bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_webtris_chunks(webtris_sites, date_from, date_to, chunk_size=20):\n",
    "    sites_dict = { s['Description']: s for s in webtris_sites }\n",
    "    req_ids = [s['Id'] for s in webtris_sites]\n",
    "    req_id_chunks = [req_ids[i:i + chunk_size] for i in range(0, len(req_ids), chunk_size)]\n",
    "    print(len(req_id_chunks))\n",
    "    for i in range(len(req_id_chunks)):\n",
    "        print(f'Downloading chunk {i:03}...')\n",
    "        chunk_data = get_chunk(req_id_chunks[i], date_from=date_from, date_to=date_to)\n",
    "        joined_data = join_site_info(chunk_data, sites_dict)\n",
    "        save_json_rows(joined_data, f'webtris_chunk_{date_from}_{date_to}_{i:03}')\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "# download_webtris_chunks(webtris_sites, '2019-07-01', '2019-07-31')\n",
    "# download_webtris_chunks(webtris_sites, '2019-08-01', '2019-08-31')\n",
    "# download_webtris_chunks(webtris_sites, '2019-09-01', '2019-09-30')\n",
    "# download_webtris_chunks(webtris_sites, '2019-10-01', '2019-10-31')\n",
    "# download_webtris_chunks(webtris_sites, '2019-11-01', '2019-11-30')\n",
    "# download_webtris_chunks(webtris_sites, '2019-12-01', '2019-12-31')\n",
    "# download_webtris_chunks(webtris_sites, '2020-01-01', '2020-01-31')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d10d3d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_from_time_bin(tb, do_floor=True):\n",
    "    h, m = tb[10:].split(':')\n",
    "    t = int(h) * 4 + int(float(m) / 15)\n",
    "    if not do_floor:\n",
    "        return t\n",
    "    # T4c speed is floored, counters seem ceiled --> subtract 1\n",
    "    t -= 1\n",
    "    if t < 0:\n",
    "        t = 95\n",
    "    return t\n",
    "\n",
    "def day_from_time_bin(tb, do_floor=True):\n",
    "    if do_floor and t_from_time_bin(tb) == 95:\n",
    "        d = datetime.strptime(tb, '%Y-%m-%d %H:%M') - timedelta(days=1)\n",
    "        return d.strftime('%Y-%m-%d')\n",
    "    return tb[:10]\n",
    "\n",
    "def convert_webtris_chunks(do_floor=True):\n",
    "    chunk_files = sorted((LONDON_PATH / 'downloads').glob('webtris_chunk_*.json'))\n",
    "    df = pd.concat([pd.read_json(cf,  lines=True) for cf in chunk_files])\n",
    "    df['id'] = df['id'].astype(str)\n",
    "    df['heading'] = -1\n",
    "    df['time_bin'] = [x[2] for x in df['time_bins']]\n",
    "    df = df.rename(columns={'speed': 'speed_counter'})\n",
    "    df['t'] = [t_from_time_bin(tb, do_floor) for tb in df['time_bin']]\n",
    "    df['day'] = [day_from_time_bin(tb, do_floor) for tb in df['time_bin']]\n",
    "    df = df[['id', 'name', 'lat', 'lon', 'heading', 'time_bin', 'volume', 'speed_counter', 't', 'day']]\n",
    "    return df\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "# webtris_df = convert_webtris_chunks()\n",
    "# webtris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd0d4149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment if processing data\n",
    "# webtris_df['name'] = webtris_df['name'].astype(str)\n",
    "# webtris_df.to_parquet(LONDON_PATH / 'speed' / 'webtris_london_201907-202001.parquet', compression=\"snappy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca76c8a",
   "metadata": {},
   "source": [
    "Read TfL TIMS locations (additional data, currently not used for validations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f4684a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'roads.data.tfl.gov.uk'\n",
    "prefix = 'TIMS/'\n",
    "s3_client = boto3.client('s3')\n",
    "    \n",
    "def get_tims_csv_files(limit=-1):\n",
    "    tims_csv_files = []\n",
    "    paginator = s3_client.get_paginator(\"list_objects_v2\")\n",
    "    for page in paginator.paginate(Bucket=bucket, Prefix=prefix, Delimiter='/'):\n",
    "        pf = [c['Key'] for c in page[\"Contents\"] if c['Key'].endswith('.csv')]\n",
    "        tims_csv_files.extend(pf)\n",
    "        if limit > 0 and len(tims_csv_files) >= limit:\n",
    "            return tims_csv_files[:limit]\n",
    "    return tims_csv_files\n",
    "\n",
    "def read_tims_csv_file(csv_file):\n",
    "    response = s3_client.get_object(Bucket=bucket, Key=csv_file)\n",
    "    return pd.read_csv(response.get(\"Body\"))\n",
    "\n",
    "def read_tims_day(day):\n",
    "    ts = datetime.strptime(day, '%Y-%m-%d')\n",
    "    tims_day_file = LONDON_PATH / 'downloads' /  f'tims_{day}.parquet'\n",
    "    if os.path.exists(tims_day_file):\n",
    "        return pd.read_parquet(tims_day_file)\n",
    "    file_prefix = f'detdata{ts.day:02d}{ts.month:02d}{ts.year:04d}'\n",
    "    files = [fp for fp in tims_csv_files if file_prefix in fp]\n",
    "    print(f'Downloading {len(files)} files for {day}')\n",
    "    df = pd.concat([read_tims_csv_file(fp) for fp in files])\n",
    "    tims_day_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "    df.to_parquet(tims_day_file, compression=\"snappy\")\n",
    "    return df\n",
    "\n",
    "tims_csv_files = get_tims_csv_files()\n",
    "len(tims_csv_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "1a992aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>NODE</th>\n",
       "      <th>EASTING</th>\n",
       "      <th>NORTHING</th>\n",
       "      <th>FLOW_ACTUAL_15M</th>\n",
       "      <th>SAT_BANDINGS</th>\n",
       "      <th>DETECTOR_NO</th>\n",
       "      <th>TOTAL_DETECTOR_NO</th>\n",
       "      <th>DETECTOR_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-03T23:44:00Z</td>\n",
       "      <td>14/013</td>\n",
       "      <td>544386.20</td>\n",
       "      <td>186690.59</td>\n",
       "      <td>193</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-03T23:44:00Z</td>\n",
       "      <td>14/015</td>\n",
       "      <td>543595.64</td>\n",
       "      <td>186425.27</td>\n",
       "      <td>297</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-03T23:44:00Z</td>\n",
       "      <td>14/016</td>\n",
       "      <td>540276.96</td>\n",
       "      <td>188758.87</td>\n",
       "      <td>61</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-03T23:44:00Z</td>\n",
       "      <td>14/019</td>\n",
       "      <td>542027.01</td>\n",
       "      <td>189905.20</td>\n",
       "      <td>139</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-03T23:44:00Z</td>\n",
       "      <td>14/020</td>\n",
       "      <td>540064.79</td>\n",
       "      <td>189082.82</td>\n",
       "      <td>129</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47027</th>\n",
       "      <td>2019-01-04T23:43:00Z</td>\n",
       "      <td>26/216</td>\n",
       "      <td>510671.00</td>\n",
       "      <td>185236.00</td>\n",
       "      <td>157</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47028</th>\n",
       "      <td>2019-01-04T23:43:00Z</td>\n",
       "      <td>27/001</td>\n",
       "      <td>521599.00</td>\n",
       "      <td>180897.40</td>\n",
       "      <td>391</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47029</th>\n",
       "      <td>2019-01-04T23:43:00Z</td>\n",
       "      <td>27/002</td>\n",
       "      <td>520569.57</td>\n",
       "      <td>181719.59</td>\n",
       "      <td>277</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47030</th>\n",
       "      <td>2019-01-04T23:43:00Z</td>\n",
       "      <td>27/004</td>\n",
       "      <td>518540.00</td>\n",
       "      <td>182590.00</td>\n",
       "      <td>372</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47031</th>\n",
       "      <td>2019-01-04T23:43:00Z</td>\n",
       "      <td>27/010</td>\n",
       "      <td>518652.32</td>\n",
       "      <td>181170.40</td>\n",
       "      <td>528</td>\n",
       "      <td>0-79%</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4624094 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  TIMESTAMP    NODE    EASTING   NORTHING  FLOW_ACTUAL_15M  \\\n",
       "0      2019-01-03T23:44:00Z  14/013  544386.20  186690.59              193   \n",
       "1      2019-01-03T23:44:00Z  14/015  543595.64  186425.27              297   \n",
       "2      2019-01-03T23:44:00Z  14/016  540276.96  188758.87               61   \n",
       "3      2019-01-03T23:44:00Z  14/019  542027.01  189905.20              139   \n",
       "4      2019-01-03T23:44:00Z  14/020  540064.79  189082.82              129   \n",
       "...                     ...     ...        ...        ...              ...   \n",
       "47027  2019-01-04T23:43:00Z  26/216  510671.00  185236.00              157   \n",
       "47028  2019-01-04T23:43:00Z  27/001  521599.00  180897.40              391   \n",
       "47029  2019-01-04T23:43:00Z  27/002  520569.57  181719.59              277   \n",
       "47030  2019-01-04T23:43:00Z  27/004  518540.00  182590.00              372   \n",
       "47031  2019-01-04T23:43:00Z  27/010  518652.32  181170.40              528   \n",
       "\n",
       "      SAT_BANDINGS  DETECTOR_NO  TOTAL_DETECTOR_NO  DETECTOR_RATE  \n",
       "0            0-79%            3                  6           0.50  \n",
       "1            0-79%            3                  4           0.75  \n",
       "2            0-79%            4                  6           0.67  \n",
       "3            0-79%            6                  6           1.00  \n",
       "4            0-79%            3                  4           0.75  \n",
       "...            ...          ...                ...            ...  \n",
       "47027        0-79%            3                  3           1.00  \n",
       "47028        0-79%           10                 10           1.00  \n",
       "47029        0-79%            5                  8           0.63  \n",
       "47030        0-79%           10                 10           1.00  \n",
       "47031        0-79%            1                  3           0.33  \n",
       "\n",
       "[4624094 rows x 9 columns]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tims_df = read_tims_day('2019-01-04')\n",
    "tims_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "03639443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating 13045333 tims rows\n",
      "Found 3882 unique locations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/t4c22/lib/python3.10/site-packages/pandas/core/dtypes/cast.py:128: ShapelyDeprecationWarning: The array interface is deprecated and will no longer work in Shapely 2.0. Convert the '.coords' to a numpy array instead.\n",
      "  arr = construct_1d_object_array_from_listlike(values)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00/002</td>\n",
       "      <td>51.514163</td>\n",
       "      <td>-0.104402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00/003</td>\n",
       "      <td>51.511618</td>\n",
       "      <td>-0.075350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00/004</td>\n",
       "      <td>51.517597</td>\n",
       "      <td>-0.107617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00/005</td>\n",
       "      <td>51.511020</td>\n",
       "      <td>-0.108040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00/006</td>\n",
       "      <td>51.511665</td>\n",
       "      <td>-0.104276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3877</th>\n",
       "      <td>32/224</td>\n",
       "      <td>51.632029</td>\n",
       "      <td>-0.073554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3878</th>\n",
       "      <td>32/225</td>\n",
       "      <td>51.631973</td>\n",
       "      <td>-0.073398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3879</th>\n",
       "      <td>32/228</td>\n",
       "      <td>51.629826</td>\n",
       "      <td>-0.097257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3880</th>\n",
       "      <td>32/229</td>\n",
       "      <td>51.631823</td>\n",
       "      <td>-0.095122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3881</th>\n",
       "      <td>32/999</td>\n",
       "      <td>49.766807</td>\n",
       "      <td>-7.557160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3882 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        lat       lon\n",
       "0     00/002  51.514163 -0.104402\n",
       "1     00/003  51.511618 -0.075350\n",
       "2     00/004  51.517597 -0.107617\n",
       "3     00/005  51.511020 -0.108040\n",
       "4     00/006  51.511665 -0.104276\n",
       "...      ...        ...       ...\n",
       "3877  32/224  51.632029 -0.073554\n",
       "3878  32/225  51.631973 -0.073398\n",
       "3879  32/228  51.629826 -0.097257\n",
       "3880  32/229  51.631823 -0.095122\n",
       "3881  32/999  49.766807 -7.557160\n",
       "\n",
       "[3882 rows x 3 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gbng = pyproj.CRS('EPSG:27700')\n",
    "wgs84 = pyproj.CRS('EPSG:4326')\n",
    "project = pyproj.Transformer.from_crs(gbng, wgs84, always_xy=True).transform\n",
    "\n",
    "def en2ll(e, n):\n",
    "    try:\n",
    "        return transform(project, Point(e, n))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return Point(0, 0)\n",
    "\n",
    "def get_projected_point(r):\n",
    "    return en2ll(float(r['EASTING']), float(r['NORTHING']))\n",
    "\n",
    "def get_tims_locations(df):\n",
    "    df['id'] = df['NODE']\n",
    "    print(f'Aggregating {len(df)} tims rows')\n",
    "    df = df[['id', 'EASTING', 'NORTHING']].groupby(['id', 'EASTING', 'NORTHING']).min().reset_index()\n",
    "    print(f'Found {len(df)} unique locations')\n",
    "    df['geometry'] = df.apply(get_projected_point, axis=1)\n",
    "    df = geopandas.GeoDataFrame(df, geometry='geometry')\n",
    "    df['lon'] = df.geometry.x\n",
    "    df['lat'] = df.geometry.y\n",
    "    return df[['id', 'lat', 'lon']]\n",
    "\n",
    "# Reading locations from different months to capture newly added or relevant temporary locations.\n",
    "tims_locations = get_tims_locations(pd.concat([\n",
    "    read_tims_day('2019-01-04'),  read_tims_day('2019-07-20'), read_tims_day('2020-02-10')\n",
    "])) \n",
    "tims_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "94c33d7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Name</th>\n",
       "      <th>Description</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>Status</th>\n",
       "      <th>lat_bin</th>\n",
       "      <th>lon_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MIDAS site at M4/2295A2 priority 1 on link 105...</td>\n",
       "      <td>M4/2295A2</td>\n",
       "      <td>-0.520380</td>\n",
       "      <td>51.493012</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>5149300</td>\n",
       "      <td>-52100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>MIDAS site at M25/5764B priority 1 on link 199...</td>\n",
       "      <td>M25/5764B</td>\n",
       "      <td>0.283162</td>\n",
       "      <td>51.575617</td>\n",
       "      <td>Active</td>\n",
       "      <td>5157500</td>\n",
       "      <td>28299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>MIDAS site at M25/4876A priority 1 on link 199...</td>\n",
       "      <td>M25/4876A</td>\n",
       "      <td>-0.538796</td>\n",
       "      <td>51.433749</td>\n",
       "      <td>Active</td>\n",
       "      <td>5143300</td>\n",
       "      <td>-53900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>MIDAS site at A2/8392M priority 1 on link 2000...</td>\n",
       "      <td>A2/8392M</td>\n",
       "      <td>0.381381</td>\n",
       "      <td>51.408466</td>\n",
       "      <td>Active</td>\n",
       "      <td>5140800</td>\n",
       "      <td>38100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>MIDAS site at M2/8460A priority 1 on link 2000...</td>\n",
       "      <td>M2/8460A</td>\n",
       "      <td>0.465564</td>\n",
       "      <td>51.386570</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>5138600</td>\n",
       "      <td>46500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4251</th>\n",
       "      <td>19757</td>\n",
       "      <td>MIDAS site at M4/2443B priority 1 on link 1050...</td>\n",
       "      <td>M4/2443B</td>\n",
       "      <td>-0.713142</td>\n",
       "      <td>51.499332</td>\n",
       "      <td>Active</td>\n",
       "      <td>5149900</td>\n",
       "      <td>-71400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4252</th>\n",
       "      <td>19758</td>\n",
       "      <td>MIDAS site at M4/2390A priority 1 on link 1050...</td>\n",
       "      <td>M4/2390A</td>\n",
       "      <td>-0.643031</td>\n",
       "      <td>51.508811</td>\n",
       "      <td>Active</td>\n",
       "      <td>5150800</td>\n",
       "      <td>-64400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4253</th>\n",
       "      <td>19759</td>\n",
       "      <td>MIDAS site at M4/2241A priority 1 on link 1991...</td>\n",
       "      <td>M4/2241A</td>\n",
       "      <td>-0.442319</td>\n",
       "      <td>51.494644</td>\n",
       "      <td>Active</td>\n",
       "      <td>5149400</td>\n",
       "      <td>-44300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4254</th>\n",
       "      <td>19761</td>\n",
       "      <td>MIDAS site at M4/2433A priority 1 on link 1050...</td>\n",
       "      <td>M4/2433A</td>\n",
       "      <td>-0.699329</td>\n",
       "      <td>51.500735</td>\n",
       "      <td>Active</td>\n",
       "      <td>5150000</td>\n",
       "      <td>-70000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4255</th>\n",
       "      <td>19762</td>\n",
       "      <td>MIDAS site at M4/2287B priority 1 on link 1990...</td>\n",
       "      <td>M4/2287B</td>\n",
       "      <td>-0.508672</td>\n",
       "      <td>51.493762</td>\n",
       "      <td>Active</td>\n",
       "      <td>5149300</td>\n",
       "      <td>-50900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4256 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                               Name Description  \\\n",
       "0         1  MIDAS site at M4/2295A2 priority 1 on link 105...   M4/2295A2   \n",
       "1         5  MIDAS site at M25/5764B priority 1 on link 199...   M25/5764B   \n",
       "2         8  MIDAS site at M25/4876A priority 1 on link 199...   M25/4876A   \n",
       "3        14  MIDAS site at A2/8392M priority 1 on link 2000...    A2/8392M   \n",
       "4        16  MIDAS site at M2/8460A priority 1 on link 2000...    M2/8460A   \n",
       "...     ...                                                ...         ...   \n",
       "4251  19757  MIDAS site at M4/2443B priority 1 on link 1050...    M4/2443B   \n",
       "4252  19758  MIDAS site at M4/2390A priority 1 on link 1050...    M4/2390A   \n",
       "4253  19759  MIDAS site at M4/2241A priority 1 on link 1991...    M4/2241A   \n",
       "4254  19761  MIDAS site at M4/2433A priority 1 on link 1050...    M4/2433A   \n",
       "4255  19762  MIDAS site at M4/2287B priority 1 on link 1990...    M4/2287B   \n",
       "\n",
       "           lon        lat    Status  lat_bin  lon_bin  \n",
       "0    -0.520380  51.493012  Inactive  5149300   -52100  \n",
       "1     0.283162  51.575617    Active  5157500    28299  \n",
       "2    -0.538796  51.433749    Active  5143300   -53900  \n",
       "3     0.381381  51.408466    Active  5140800    38100  \n",
       "4     0.465564  51.386570  Inactive  5138600    46500  \n",
       "...        ...        ...       ...      ...      ...  \n",
       "4251 -0.713142  51.499332    Active  5149900   -71400  \n",
       "4252 -0.643031  51.508811    Active  5150800   -64400  \n",
       "4253 -0.442319  51.494644    Active  5149400   -44300  \n",
       "4254 -0.699329  51.500735    Active  5150000   -70000  \n",
       "4255 -0.508672  51.493762    Active  5149300   -50900  \n",
       "\n",
       "[4256 rows x 8 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dataframe with all london locations (WEBTRIS and TIMS)\n",
    "webtris_locations = pd.DataFrame.from_records(webtris_sites).rename(\n",
    "    columns={'Id': 'id', 'Latitude': 'lat', 'Longitude': 'lon'})\n",
    "webtris_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ea307a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>28</td>\n",
       "      <td>51.268629</td>\n",
       "      <td>-0.166750</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.16675 51.26863)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>46</td>\n",
       "      <td>51.264317</td>\n",
       "      <td>-0.132305</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.13230 51.26432)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>57</td>\n",
       "      <td>51.273244</td>\n",
       "      <td>0.063816</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (0.06382 51.27324)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>75</td>\n",
       "      <td>51.259332</td>\n",
       "      <td>-0.108098</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.10810 51.25933)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>80</td>\n",
       "      <td>51.258246</td>\n",
       "      <td>-0.053938</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.05394 51.25825)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3683</th>\n",
       "      <td>32/210</td>\n",
       "      <td>51.612580</td>\n",
       "      <td>-0.113407</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.11341 51.61258)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3684</th>\n",
       "      <td>32/224</td>\n",
       "      <td>51.632029</td>\n",
       "      <td>-0.073554</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.07355 51.63203)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3685</th>\n",
       "      <td>32/225</td>\n",
       "      <td>51.631973</td>\n",
       "      <td>-0.073398</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.07340 51.63197)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>32/228</td>\n",
       "      <td>51.629826</td>\n",
       "      <td>-0.097257</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.09726 51.62983)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3687</th>\n",
       "      <td>32/229</td>\n",
       "      <td>51.631823</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>-1</td>\n",
       "      <td>POINT (-0.09512 51.63182)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3824 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id        lat       lon  heading                   geometry\n",
       "7         28  51.268629 -0.166750       -1  POINT (-0.16675 51.26863)\n",
       "13        46  51.264317 -0.132305       -1  POINT (-0.13230 51.26432)\n",
       "17        57  51.273244  0.063816       -1   POINT (0.06382 51.27324)\n",
       "22        75  51.259332 -0.108098       -1  POINT (-0.10810 51.25933)\n",
       "25        80  51.258246 -0.053938       -1  POINT (-0.05394 51.25825)\n",
       "...      ...        ...       ...      ...                        ...\n",
       "3683  32/210  51.612580 -0.113407       -1  POINT (-0.11341 51.61258)\n",
       "3684  32/224  51.632029 -0.073554       -1  POINT (-0.07355 51.63203)\n",
       "3685  32/225  51.631973 -0.073398       -1  POINT (-0.07340 51.63197)\n",
       "3686  32/228  51.629826 -0.097257       -1  POINT (-0.09726 51.62983)\n",
       "3687  32/229  51.631823 -0.095122       -1  POINT (-0.09512 51.63182)\n",
       "\n",
       "[3824 rows x 5 columns]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "london_locations = pd.concat([webtris_locations[['id', 'lat', 'lon']], tims_locations[['id', 'lat', 'lon']]])\n",
    "london_locations = get_gdf(london_locations, bbox=LONDON_BBOX)\n",
    "london_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09594e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the counter locations to geojson\n",
    "london_locations.to_file(LONDON_PATH / 'counter_locations.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "5d30dbf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 4578603/13710719 records for 2019-07-01\n",
      "Collected 327551 time bin volumes for 2019-07-01\n",
      "Read 4610633/13796313 records for 2019-07-02\n",
      "Collected 329353 time bin volumes for 2019-07-02\n",
      "Read 4618687/13837389 records for 2019-07-03\n",
      "Collected 330089 time bin volumes for 2019-07-03\n",
      "Read 4609916/13840808 records for 2019-07-04\n",
      "Collected 329579 time bin volumes for 2019-07-04\n",
      "Downloading 96 files for 2019-07-06\n",
      "Read 4624316/13782294 records for 2019-07-05\n",
      "Collected 330196 time bin volumes for 2019-07-05\n",
      "Downloading 96 files for 2019-07-07\n",
      "Read 4553215/12969267 records for 2019-07-06\n",
      "Collected 326348 time bin volumes for 2019-07-06\n",
      "Downloading 96 files for 2019-07-08\n",
      "Read 3737830/12675517 records for 2019-07-07\n",
      "Collected 269946 time bin volumes for 2019-07-07\n",
      "Downloading 96 files for 2019-07-09\n",
      "Read 4373676/12786737 records for 2019-07-08\n",
      "Collected 309826 time bin volumes for 2019-07-08\n",
      "Downloading 96 files for 2019-07-10\n",
      "Read 4667886/13667681 records for 2019-07-09\n",
      "Collected 330227 time bin volumes for 2019-07-09\n",
      "Downloading 96 files for 2019-07-11\n",
      "Read 4682069/14038646 records for 2019-07-10\n",
      "Collected 331101 time bin volumes for 2019-07-10\n",
      "Downloading 96 files for 2019-07-12\n",
      "Read 4691997/14073706 records for 2019-07-11\n",
      "Collected 331273 time bin volumes for 2019-07-11\n",
      "Downloading 89 files for 2019-07-13\n",
      "Read 4712730/13702497 records for 2019-07-12\n",
      "Collected 332545 time bin volumes for 2019-07-12\n",
      "Downloading 61 files for 2019-07-14\n",
      "Read 4068924/12074038 records for 2019-07-13\n",
      "Collected 288333 time bin volumes for 2019-07-13\n",
      "Downloading 96 files for 2019-07-15\n",
      "Read 3279791/12011387 records for 2019-07-14\n",
      "Collected 233164 time bin volumes for 2019-07-14\n",
      "Downloading 96 files for 2019-07-16\n",
      "Read 4649165/12385859 records for 2019-07-15\n",
      "Collected 328792 time bin volumes for 2019-07-15\n",
      "Downloading 96 files for 2019-07-17\n",
      "Read 4683764/14001870 records for 2019-07-16\n",
      "Collected 330730 time bin volumes for 2019-07-16\n",
      "Downloading 96 files for 2019-07-18\n",
      "Read 4679540/14043455 records for 2019-07-17\n",
      "Collected 331443 time bin volumes for 2019-07-17\n",
      "Downloading 96 files for 2019-07-19\n",
      "Read 4684360/14032932 records for 2019-07-18\n",
      "Collected 331455 time bin volumes for 2019-07-18\n",
      "Downloading 96 files for 2019-07-20\n",
      "Read 4680437/13991591 records for 2019-07-19\n",
      "Collected 330603 time bin volumes for 2019-07-19\n",
      "Downloading 96 files for 2019-07-21\n",
      "Read 4634418/13844277 records for 2019-07-20\n",
      "Collected 328979 time bin volumes for 2019-07-20\n",
      "Downloading 96 files for 2019-07-22\n",
      "Read 4516976/13800388 records for 2019-07-21\n",
      "Collected 323044 time bin volumes for 2019-07-21\n",
      "Downloading 96 files for 2019-07-23\n",
      "Read 4636644/13828330 records for 2019-07-22\n",
      "Collected 328633 time bin volumes for 2019-07-22\n",
      "Downloading 96 files for 2019-07-24\n",
      "Read 4666357/13974272 records for 2019-07-23\n",
      "Collected 330090 time bin volumes for 2019-07-23\n",
      "Downloading 96 files for 2019-07-25\n",
      "Read 4675841/14044151 records for 2019-07-24\n",
      "Collected 330325 time bin volumes for 2019-07-24\n",
      "Downloading 96 files for 2019-07-26\n",
      "Read 4708052/14150053 records for 2019-07-25\n",
      "Collected 330855 time bin volumes for 2019-07-25\n",
      "Downloading 96 files for 2019-07-27\n",
      "Read 4783403/14056933 records for 2019-07-26\n",
      "Collected 333384 time bin volumes for 2019-07-26\n",
      "Downloading 96 files for 2019-07-28\n",
      "Read 4579000/13910069 records for 2019-07-27\n",
      "Collected 325681 time bin volumes for 2019-07-27\n",
      "Downloading 96 files for 2019-07-29\n",
      "Read 4533367/13750033 records for 2019-07-28\n",
      "Collected 325296 time bin volumes for 2019-07-28\n",
      "Downloading 96 files for 2019-07-30\n",
      "Read 4620057/13888592 records for 2019-07-29\n",
      "Collected 328954 time bin volumes for 2019-07-29\n",
      "Downloading 96 files for 2019-07-31\n",
      "Read 4733659/14142494 records for 2019-07-30\n",
      "Collected 332398 time bin volumes for 2019-07-30\n",
      "Downloading 96 files for 2019-08-01\n",
      "Read 4806423/14084805 records for 2019-07-31\n",
      "Collected 334164 time bin volumes for 2019-07-31\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>day</th>\n",
       "      <th>t</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00/002</td>\n",
       "      <td>51.514163</td>\n",
       "      <td>-0.104402</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>96.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00/003</td>\n",
       "      <td>51.511618</td>\n",
       "      <td>-0.075350</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>40.933333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00/004</td>\n",
       "      <td>51.517597</td>\n",
       "      <td>-0.107617</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>144.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00/005</td>\n",
       "      <td>51.511020</td>\n",
       "      <td>-0.108040</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>313.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00/006</td>\n",
       "      <td>51.511665</td>\n",
       "      <td>-0.104276</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>0</td>\n",
       "      <td>81.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334158</th>\n",
       "      <td>32/205</td>\n",
       "      <td>51.613728</td>\n",
       "      <td>-0.124565</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>95</td>\n",
       "      <td>437.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334159</th>\n",
       "      <td>32/207</td>\n",
       "      <td>51.612491</td>\n",
       "      <td>-0.116930</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>95</td>\n",
       "      <td>534.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334160</th>\n",
       "      <td>32/209</td>\n",
       "      <td>51.612679</td>\n",
       "      <td>-0.113519</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>95</td>\n",
       "      <td>580.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334161</th>\n",
       "      <td>32/210</td>\n",
       "      <td>51.612580</td>\n",
       "      <td>-0.113407</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>95</td>\n",
       "      <td>261.928571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334162</th>\n",
       "      <td>32/229</td>\n",
       "      <td>51.631823</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>95</td>\n",
       "      <td>48.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8750306 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        lat       lon  heading         day   t      volume\n",
       "0       00/002  51.514163 -0.104402     -1.0  2019-07-01   0   96.866667\n",
       "1       00/003  51.511618 -0.075350     -1.0  2019-07-01   0   40.933333\n",
       "2       00/004  51.517597 -0.107617     -1.0  2019-07-01   0  144.866667\n",
       "3       00/005  51.511020 -0.108040     -1.0  2019-07-01   0  313.333333\n",
       "4       00/006  51.511665 -0.104276     -1.0  2019-07-01   0   81.266667\n",
       "...        ...        ...       ...      ...         ...  ..         ...\n",
       "334158  32/205  51.613728 -0.124565     -1.0  2019-07-31  95  437.571429\n",
       "334159  32/207  51.612491 -0.116930     -1.0  2019-07-31  95  534.000000\n",
       "334160  32/209  51.612679 -0.113519     -1.0  2019-07-31  95  580.000000\n",
       "334161  32/210  51.612580 -0.113407     -1.0  2019-07-31  95  261.928571\n",
       "334162  32/229  51.631823 -0.095122     -1.0  2019-07-31  95   48.200000\n",
       "\n",
       "[8750306 rows x 7 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_volumes(time_bins, volumes, num_bins=96):\n",
    "    result = []\n",
    "    for ts, vs in zip(time_bins, volumes):\n",
    "        res_volumes = [-1 for _ in range(num_bins)]\n",
    "        for idx, v in zip(ts, vs):\n",
    "            assert(0 <= idx < num_bins)\n",
    "            res_volumes[idx] = int(round(float(v)))\n",
    "        result.append(res_volumes)\n",
    "    return result\n",
    "\n",
    "\n",
    "def process_volume_normalization(df):\n",
    "    df = df.groupby(by=['day', 'id', 'lat', 'lon', 'heading']).agg(list).reset_index()\n",
    "    df['volume'] = normalize_volumes(df['t'], df['volume'])\n",
    "    print(f'Aggregated {len(df)} counter volume lists')\n",
    "    return df #[['id', 'lat', 'lon', 'heading', 'day', 't', 'volume']]\n",
    "\n",
    "\n",
    "def process_tims_day(day):\n",
    "    day_ts = datetime.strptime(day, '%Y-%m-%d')\n",
    "    dfa =pd.concat([\n",
    "        read_tims_day((day_ts - timedelta(days=1)).strftime('%Y-%m-%d')),\n",
    "        read_tims_day(day),\n",
    "        read_tims_day((day_ts + timedelta(days=1)).strftime('%Y-%m-%d'))\n",
    "    ])\n",
    "    raw_num_records = len(dfa)\n",
    "    dfa = dfa[dfa['TIMESTAMP'].str.startswith(day)]\n",
    "    print(f'Read {len(dfa)}/{raw_num_records} records for {day}')\n",
    "    raw_num_records = len(dfa)\n",
    "    \n",
    "    # Filter invalid records, convert the fields and generate time bins\n",
    "    dfa['ts'] = pd.to_datetime(dfa['TIMESTAMP'], infer_datetime_format=True, errors='coerce')\n",
    "    dfa = dfa[dfa['ts'].notna()]\n",
    "    dfa['t'] = dfa['ts'].dt.hour * 4 + (dfa['ts'].dt.minute/15).astype(int)\n",
    "    dfa['day'] = day\n",
    "    dfa = dfa.drop(columns=['TIMESTAMP'])\n",
    "    dfa = dfa.rename(columns={\n",
    "        'NODE': 'id', 'EASTING': 'east', 'NORTHING': 'north', 'FLOW_ACTUAL_15M': 'flow_15m',\n",
    "        'SAT_BANDINGS': 'sat_bandings', 'DETECTOR_NO': 'det_no', 'TOTAL_DETECTOR_NO': 'num_det',\n",
    "        'DETECTOR_RATE': 'detector_rate'\n",
    "    })\n",
    "    dfa['east'] = pd.to_numeric(dfa['east'], errors='coerce')\n",
    "    dfa['north'] = pd.to_numeric(dfa['north'], errors='coerce')\n",
    "    dfa = dfa[dfa['east'].notna() & dfa['north'].notna()]\n",
    "    if len(dfa) < raw_num_records:\n",
    "        print(f'  filtered {raw_num_records - len(dfa)} invalid records')\n",
    "    dfa['flow_15m'] = pd.to_numeric(dfa['flow_15m'], errors='coerce')\n",
    "    dfa['det_no'] = pd.to_numeric(dfa['det_no'], errors='coerce')\n",
    "    dfa['num_det'] = pd.to_numeric(dfa['num_det'], errors='coerce')\n",
    "    dfa['detector_rate'] = pd.to_numeric(dfa['detector_rate'], errors='coerce')\n",
    "    \n",
    "    # Aggregate to average 15 minute volumes and generate one row per day\n",
    "    df = dfa[['day', 't', 'id', 'east', 'north', 'flow_15m']].groupby(\n",
    "        by=['day', 't', 'id', 'east', 'north']).mean().reset_index()\n",
    "    df = df.rename(columns={'flow_15m': 'volume'})\n",
    "    print(f'Collected {len(df)} time bin volumes for {day}')\n",
    "    df['lat'] = [en2ll(float(e), float(n)).y for e, n in zip(df['east'], df['north'])]\n",
    "    df['lon'] = [en2ll(float(e), float(n)).x for e, n in zip(df['east'], df['north'])]\n",
    "    df['heading'] = -1.0\n",
    "    return df[['id', 'lat', 'lon', 'heading', 'day', 't', 'volume']]\n",
    "\n",
    "\n",
    "def process_tims_month(year, month):\n",
    "    tims_month_file = LONDON_PATH / 'flow' / f'counters_tims_{year:04d}-{month:02d}.parquet'\n",
    "    if os.path.exists(tims_month_file):\n",
    "        print(f'File {tims_month_file} exists already')\n",
    "        return\n",
    "    \n",
    "    day_dfs = []\n",
    "    _, n = monthrange(year, month)\n",
    "    for i in range(1, n + 1):\n",
    "        day = f'{year:04d}-{month:02d}-{i:02d}'\n",
    "        df = process_tims_day(day)\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        day_dfs.append(df)\n",
    "    month_df = pd.concat(day_dfs)\n",
    "    \n",
    "    lat_min, lat_max, lon_min, lon_max = tuple([ll/100000 for ll in LONDON_BBOX])\n",
    "    month_df = month_df[\n",
    "        (month_df['lat'] >= lat_min) & (month_df['lat'] <= lat_max) &\n",
    "        (month_df['lon'] >= lon_min) & (month_df['lon'] <= lon_max)]\n",
    "    \n",
    "    tims_month_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "    month_df.to_parquet(tims_month_file, compression=\"snappy\")\n",
    "    return month_df\n",
    "\n",
    "\n",
    "# process_tims_day('2019-07-04')\n",
    "# TODO: uncomment if processing data\n",
    "process_tims_month(2019, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7ea55",
   "metadata": {},
   "source": [
    "Normalize Webtris and merge with TIMS data for a single merged volume file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "85f0f805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated 1054 counter volume lists\n",
      "Aggregated 100122 counter volume lists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>51.562738</td>\n",
       "      <td>-2.532792</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[138, 138, 106, 86, 84, 79, 60, 49, 62, 65, 56...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104</td>\n",
       "      <td>51.426911</td>\n",
       "      <td>0.238597</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>106</td>\n",
       "      <td>51.467634</td>\n",
       "      <td>-0.508905</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[346, 293, 279, 278, 256, 216, 201, 200, 223, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>109</td>\n",
       "      <td>51.329145</td>\n",
       "      <td>0.516358</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>110</td>\n",
       "      <td>51.489845</td>\n",
       "      <td>-0.369827</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>[263, 241, 181, 145, 119, 118, 72, 83, 71, 76,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100117</th>\n",
       "      <td>32/210</td>\n",
       "      <td>51.612580</td>\n",
       "      <td>-0.113407</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100118</th>\n",
       "      <td>32/224</td>\n",
       "      <td>51.632029</td>\n",
       "      <td>-0.073554</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100119</th>\n",
       "      <td>32/225</td>\n",
       "      <td>51.631973</td>\n",
       "      <td>-0.073398</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100120</th>\n",
       "      <td>32/228</td>\n",
       "      <td>51.629826</td>\n",
       "      <td>-0.097257</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100121</th>\n",
       "      <td>32/229</td>\n",
       "      <td>51.631823</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>-1</td>\n",
       "      <td>2019-07-31</td>\n",
       "      <td>[58, 42, 44, 38, 28, 19, 24, 18, 13, 11, 15, 1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101176 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        lat       lon  heading         day  \\\n",
       "0          101  51.562738 -2.532792       -1  2019-07-01   \n",
       "1          104  51.426911  0.238597       -1  2019-07-01   \n",
       "2          106  51.467634 -0.508905       -1  2019-07-01   \n",
       "3          109  51.329145  0.516358       -1  2019-07-01   \n",
       "4          110  51.489845 -0.369827       -1  2019-07-01   \n",
       "...        ...        ...       ...      ...         ...   \n",
       "100117  32/210  51.612580 -0.113407       -1  2019-07-31   \n",
       "100118  32/224  51.632029 -0.073554       -1  2019-07-31   \n",
       "100119  32/225  51.631973 -0.073398       -1  2019-07-31   \n",
       "100120  32/228  51.629826 -0.097257       -1  2019-07-31   \n",
       "100121  32/229  51.631823 -0.095122       -1  2019-07-31   \n",
       "\n",
       "                                                   volume  \n",
       "0       [138, 138, 106, 86, 84, 79, 60, 49, 62, 65, 56...  \n",
       "1       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "2       [346, 293, 279, 278, 256, 216, 201, 200, 223, ...  \n",
       "3       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "4       [263, 241, 181, 145, 119, 118, 72, 83, 71, 76,...  \n",
       "...                                                   ...  \n",
       "100117  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "100118  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "100119  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -...  \n",
       "100120  [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 3...  \n",
       "100121  [58, 42, 44, 38, 28, 19, 24, 18, 13, 11, 15, 1...  \n",
       "\n",
       "[101176 rows x 6 columns]"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_london(month):\n",
    "    webtris_normalized_df = pd.read_parquet(LONDON_PATH / 'speed' / 'webtris_london_201907-202001.parquet')\n",
    "    webtris_normalized_df = webtris_normalized_df[webtris_normalized_df['day'].str.startswith(month)]\n",
    "    webtris_normalized_df = process_volume_normalization(webtris_normalized_df)\n",
    "    webtris_normalized_df = webtris_normalized_df[['id', 'lat', 'lon', 'heading', 'day', 'volume']]\n",
    "    \n",
    "    tims_normalized_df = pd.read_parquet(LONDON_PATH / 'flow' / f'counters_tims_{month}.parquet')\n",
    "    tims_normalized_df = tims_normalized_df[tims_normalized_df['day'].str.startswith(month)]\n",
    "    tims_normalized_df['heading'] = -1\n",
    "    tims_normalized_df = process_volume_normalization(tims_normalized_df)\n",
    "    tims_normalized_df = tims_normalized_df[['id', 'lat', 'lon', 'heading', 'day', 'volume']]\n",
    "    \n",
    "    london_normalized_df = pd.concat([webtris_normalized_df, tims_normalized_df])\n",
    "    london_normalized_df.to_parquet(LONDON_PATH / f'counters_normalized_{month}', compression=\"snappy\")\n",
    "    return london_normalized_df\n",
    "\n",
    "london_normalized_df = merge_london('2019-07')\n",
    "london_normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c25cd4",
   "metadata": {},
   "source": [
    "# Madrid\n",
    "\n",
    "The raw files were downloaded from https://datos.madrid.es/ in zipped CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09121cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_dcat_zips(dcat_file, prefix, month_names=False, months=None):\n",
    "    root = ET.parse(MADRID_PATH / 'downloads' / dcat_file).getroot()\n",
    "    ns = {'dcat': 'http://www.w3.org/ns/dcat#',\n",
    "          'dct': 'http://purl.org/dc/terms/'}\n",
    "    data_urls = {}\n",
    "    for entry in root.findall('.//dcat:Distribution', ns):\n",
    "        title = entry.find('dct:title', ns).text\n",
    "        url = entry.find('dcat:accessURL', ns).text\n",
    "        if url.endswith('.zip'):\n",
    "            try:\n",
    "                if month_names:\n",
    "                    locale.setlocale(locale.LC_TIME, 'es_ES.UTF-8')\n",
    "                    title = title.replace('diciiembre', 'diciembre')\n",
    "                    month = datetime.strptime(title, '%Y. %B')\n",
    "                else:\n",
    "                    month = datetime.strptime(title[6:], '%d/%m/%Y')\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "            month = datetime.strftime(month, '%Y-%m')\n",
    "            if months:\n",
    "                if not month in months:\n",
    "                    continue\n",
    "            data_urls[month] = url\n",
    "            print(f'{month}: {url}')\n",
    "            r = requests.get(url, allow_redirects=True)\n",
    "            open(MADRID_PATH / 'downloads' / f\"{prefix}-{month}.zip\", 'wb').write(r.content)\n",
    "    return data_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a1c8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment if processing data\n",
    "# url = \"https://datos.madrid.es/egob/catalogo/202468-0-intensidad-trafico.dcat\"\n",
    "# out_file = MADRID_PATH / 'downloads' / '202468-0-intensidad-trafico.dcat'\n",
    "# os.system(f\"wget -O {out_file} {url}\")\n",
    "# download_dcat_zips('202468-0-intensidad-trafico.dcat', prefix='locations', month_names=False,\n",
    "#                    months=['2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2266e7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment if processing data\n",
    "# url = \"https://datos.madrid.es/egob/catalogo/208627-0-transporte-ptomedida-historico.dcat\"\n",
    "# out_file = MADRID_PATH / 'downloads' / '208627-0-transporte-ptomedida-historico.dcat'\n",
    "# os.system(f\"wget -O {out_file} {url}\")\n",
    "# download_dcat_zips('208627-0-transporte-ptomedida-historico.dcat', prefix='data', month_names=True,\n",
    "#                    months=['2021-06', '2021-07', '2021-08', '2021-09', '2021-10', '2021-11', '2021-12'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "997f0cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpoh5uff91/pmed_ubicacion_07-2021.shp\n",
      "502 / 4519 headings differ\n",
      "2021-07\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmphaxuqyq9/pmed_ubicacion_12-2021.shp\n",
      "502 / 4571 headings differ\n",
      "2021-12\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpsgga1p9r/pmed_ubicacion_06-2021.shp\n",
      "502 / 4489 headings differ\n",
      "2021-06\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpqz91hwln/pmed_ubicacion_10-2021.shp\n",
      "503 / 4538 headings differ\n",
      "2021-10\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpijnm9krf/pmed_ubicacion_11-2021.shp\n",
      "503 / 4567 headings differ\n",
      "2021-11\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpfgcawauu/pmed_ubicacion_08-2021.shp\n",
      "502 / 4529 headings differ\n",
      "2021-08\n",
      "/var/folders/dr/jy4_0c5d3q37snprz6rhwwt40000gn/T/tmpq03mu1zb/pmed_ubicacion_09-2021.shp\n",
      "502 / 4527 headings differ\n",
      "2021-09\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4593"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import atan2, cos, sin, degrees\n",
    "from shapely.geometry import LineString, Point, MultiPoint\n",
    "from shapely.ops import transform\n",
    "from scipy.spatial import ConvexHull\n",
    "import pyproj\n",
    "\n",
    "ETRS89 = pyproj.CRS('EPSG:25830')\n",
    "WGS84 = pyproj.CRS('EPSG:4326')\n",
    "project_wgs84 = pyproj.Transformer.from_crs(ETRS89, WGS84, always_xy=True).transform\n",
    "\n",
    "def get_heading(lon1, lat1, lon2, lat2):\n",
    "    angle = atan2(lon2-lon1, lat2-lat1)\n",
    "    angle = degrees(angle)\n",
    "    if angle < 0:\n",
    "        angle += 360\n",
    "    return angle\n",
    "\n",
    "def convert_locations_shp(zip_file):\n",
    "    hdiff = 0\n",
    "    features = []\n",
    "    zf = zipfile.ZipFile(zip_file)\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        zf.extractall(tempdir)\n",
    "        shp_path = glob.glob(f'{tempdir}/*.shp')[0]\n",
    "        print(shp_path)\n",
    "        shapefile = geopandas.read_file(shp_path)\n",
    "        for index, row in shapefile.iterrows():\n",
    "            arrow_polygon = transform(project_wgs84, row['geometry'])\n",
    "            from_point = LineString([arrow_polygon.exterior.coords[2], arrow_polygon.exterior.coords[3]]).centroid\n",
    "            to_point = Point(arrow_polygon.exterior.coords[6])\n",
    "            heading = get_heading(from_point.x, from_point.y, to_point.x, to_point.y)\n",
    "            points = np.array(list(arrow_polygon.exterior.coords))\n",
    "            hull_points = points[ConvexHull(points).vertices]\n",
    "            # find shortest segment index\n",
    "            shortest_segment_len = 1e9\n",
    "            shortest_segment_idx = 0\n",
    "            shortest_segment = None\n",
    "            idxs = list(range(len(hull_points)))\n",
    "            idxs.append(0)\n",
    "            for i1, i2 in zip(idxs[:-1], idxs[1:]):\n",
    "                s = LineString([hull_points[i1], hull_points[i2]])\n",
    "                if s.length < shortest_segment_len:\n",
    "                    shortest_segment_len = s.length\n",
    "                    shortest_segment = s\n",
    "                    shortest_segment_idx = i2\n",
    "            from_point = shortest_segment.centroid\n",
    "            to_idx = shortest_segment_idx\n",
    "            for i in range(2):\n",
    "                to_idx += 1\n",
    "                if to_idx == len(hull_points):\n",
    "                    to_idx = 0\n",
    "            to_point = Point(hull_points[to_idx])\n",
    "            heading_hull = get_heading(from_point.x, from_point.y, to_point.x, to_point.y)\n",
    "            if abs(heading_hull - heading) > 0.5:\n",
    "                hdiff += 1\n",
    "                heading = heading_hull\n",
    "            features.append(geojson.Feature(geometry=geojson.Point((row['longitud'], row['latitud'])),\n",
    "            properties={\n",
    "                \"heading\": heading, \"name\": row['nombre'], \"tipo_elem\": row['tipo_elem'],\n",
    "                \"id\": int(row['id']), \"distrito\": str(row['distrito']), \"cod_cent\": str(row['cod_cent'])\n",
    "            }))\n",
    "    print(f'{hdiff} / {len(features)} headings differ')\n",
    "    feature_collection = geojson.FeatureCollection(features)\n",
    "    geojson_name = os.path.splitext(os.path.basename(zip_file))[0]\n",
    "    with open(MADRID_PATH / 'downloads' / f'{geojson_name}.geojson', 'w') as f:\n",
    "        geojson.dump(feature_collection, f)\n",
    "    return feature_collection\n",
    "\n",
    "def diff_dicts(a, b, drop_similar=True):\n",
    "    res = a.copy()\n",
    "    for k in res:\n",
    "        if k not in b:\n",
    "            res[k] = (res[k], None)\n",
    "    for k in b:\n",
    "        if k in res:\n",
    "            res[k] = (res[k], b[k])\n",
    "        else:\n",
    "            res[k] = (None, b[k])\n",
    "    if drop_similar:\n",
    "        res = {k:v for k,v in res.items() if v[0] != v[1]}\n",
    "    return res\n",
    "\n",
    "def check_diff(diff, key, tolerance):\n",
    "    if key not in diff:\n",
    "        return False\n",
    "    a, b = diff[key]\n",
    "    return abs(a-b) > tolerance\n",
    "\n",
    "def open_locations(locations_file):\n",
    "    locations_by_id = {}\n",
    "    with open(locations_file, 'r') as f:\n",
    "        fc = geojson.load(f)\n",
    "        for f in fc['features']:\n",
    "            id = f['properties']['id']\n",
    "            heading = f['properties']['heading']\n",
    "            lat = f['geometry']['coordinates'][1]\n",
    "            lon = f['geometry']['coordinates'][0]\n",
    "            name = f['properties']['name']\n",
    "            tipo_elem = f['properties']['tipo_elem']\n",
    "            distrito = f['properties']['distrito']\n",
    "            cod_cent = f['properties']['cod_cent']\n",
    "            yield {\"id\": id, \"name\":name, \"lat\":lat, \"lon\":lon, \"heading\":heading,\n",
    "                   \"tipo_elem\":tipo_elem, \"distrito\":distrito, \"cod_cent\":cod_cent}\n",
    "\n",
    "def get_merged_locations():\n",
    "    merged_locations = {}\n",
    "    for locations_zip in (MADRID_PATH / 'downloads').glob('locations-*.zip'):\n",
    "        convert_locations_shp(locations_zip)\n",
    "        month = str(locations_zip)[-11:-4]\n",
    "        print(month)\n",
    "        for l in open_locations(str(locations_zip).replace('.zip', '.geojson')):\n",
    "            id = l[\"id\"]\n",
    "            if id in merged_locations:\n",
    "                matches = False\n",
    "                for i, lo in enumerate(merged_locations[id]):\n",
    "                    diff = diff_dicts(lo['data'], l)\n",
    "                    if (check_diff(diff, 'lat', 0.0001) or \n",
    "                        check_diff(diff, 'lon', 0.0001) or \n",
    "                        check_diff(diff, 'heading', 5.0)):\n",
    "                        pass\n",
    "                    else:\n",
    "                        matches = True\n",
    "                        break\n",
    "                if matches:\n",
    "                    merged_locations[id][i]['months'].append(month)\n",
    "                else:\n",
    "                    merged_locations[id].append({'months': [month], 'data': l})\n",
    "            else:\n",
    "                merged_locations[id] = [{'months': [month], 'data': l}]\n",
    "    return merged_locations\n",
    "\n",
    "\n",
    "merged_locations = get_merged_locations()\n",
    "len(merged_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a6a4509e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "for id, mll in merged_locations.items():\n",
    "    for ml in mll:\n",
    "        props = ml['data']\n",
    "        props['valid_months'] = ','.join(ml['months'])\n",
    "        pt = geojson.Point([props['lon'], props['lat']])\n",
    "        features.append(geojson.Feature(geometry=pt, properties=props))\n",
    "\n",
    "feature_collection = geojson.FeatureCollection(features)\n",
    "with open(MADRID_PATH / 'downloads' / 'counter_locations_merged.geojson', 'w') as f:\n",
    "    geojson.dump(feature_collection, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "907c3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the counter locations to geojson\n",
    "get_gdf(geopandas.read_file(\n",
    "    MADRID_PATH / 'downloads' / 'counter_locations_merged.geojson')[['id', 'lat', 'lon', 'heading']]\n",
    "       ).to_file(MADRID_PATH / 'counter_locations.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5ca3bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from io import TextIOWrapper\n",
    "\n",
    "def time_bin_format(time):\n",
    "    return time.strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "def get_locations_by_id_and_month():\n",
    "    locations_by_id_and_month = {}\n",
    "    with open(MADRID_PATH / 'downloads' / 'counter_locations_merged.geojson', 'r') as f:\n",
    "        fc = geojson.load(f)\n",
    "        for f in fc['features']:\n",
    "            id = f['properties']['id']\n",
    "            heading = f['properties']['heading']\n",
    "            lat = f['geometry']['coordinates'][1]\n",
    "            lon = f['geometry']['coordinates'][0]\n",
    "            for valid_month in f['properties']['valid_months'].split(','):\n",
    "                if id not in locations_by_id_and_month:\n",
    "                    locations_by_id_and_month[id] = {}\n",
    "                locations_by_id_and_month[id][valid_month] = (lat, lon, heading)\n",
    "    return locations_by_id_and_month\n",
    "\n",
    "def generate_data_by_counter(month, locations_by_id_and_month):\n",
    "    count = 0\n",
    "    cf = MADRID_PATH / 'downloads'/ f'data-{month}.zip'\n",
    "    print(cf)\n",
    "    cfa = zipfile.ZipFile(cf, 'r')\n",
    "    f = cfa.open(f'{(datetime.strptime(month, \"%Y-%m\")).strftime(\"%m-%Y\")}.csv', 'r')\n",
    "    csvreader = csv.reader(TextIOWrapper(f, 'utf-8'), delimiter=';')\n",
    "    header = next(csvreader)\n",
    "    # print(header)\n",
    "    for row in csvreader:\n",
    "        # https://datos.madrid.es/FWProjects/egob/Catalogo/Transporte/Trafico/ficheros/PuntosMedidaTraficoMdrid.pdf\n",
    "        # ['id', 'fecha', 'tipo_elem', 'intensidad', 'ocupacion', 'carga', 'vmed', 'error', 'periodo_integracion']\n",
    "        # fecha --> collection time --> time bin\n",
    "        # tipo_elem --> counter type ('URB' or 'M30')\n",
    "        # intensidad --> number of vehicles in 15 minutes --> volume\n",
    "        # occupacion --> occupation time in percent [0..100] of 15 minutes\n",
    "        # carga --> congestion level in percent [0..100]\n",
    "        # vmed --> average speed (only on M30 counters)\n",
    "        locid = int(row[0])\n",
    "        if locid not in locations_by_id_and_month:\n",
    "            print(f'WARNING: unknown ID {locid}')\n",
    "            continue\n",
    "        valid_month = month\n",
    "        if valid_month not in locations_by_id_and_month[locid]:\n",
    "            # Try the months before, stupid logic but sufficient here\n",
    "            while valid_month not in locations_by_id_and_month[locid]:\n",
    "                valid_month = (pd.to_datetime(valid_month) - pd.Timedelta(\"1 day\")).strftime(\"%Y-%m\")\n",
    "                if valid_month[:4] == '2018':\n",
    "                    break\n",
    "            if valid_month not in locations_by_id_and_month[locid]:\n",
    "                print(f'WARNING: no valid month {month} for ID {locid}: {locations_by_id_and_month[locid]}')\n",
    "                continue\n",
    "        lat, lon, heading = locations_by_id_and_month[locid][valid_month]\n",
    "        volume = int(row[3])\n",
    "        occupation = float(row[4])\n",
    "        congestion_level = float(row[5])\n",
    "        speed_avg = float(row[6])\n",
    "        collection_time = row[1]\n",
    "        time_bin = time_bin_format(datetime.strptime(collection_time, '%Y-%m-%d %H:%M:%S'))\n",
    "        count += 1\n",
    "        if count % 1000000 == 0:\n",
    "            print(count)\n",
    "        yield {'id': locid, 'lat': lat, 'lon': lon, 'heading': heading, 'time_bin': time_bin, 'type': row[2],\n",
    "               'volume': volume, 'occupation': occupation, 'congestion_level': congestion_level,\n",
    "               'speed_avg': speed_avg}\n",
    "\n",
    "def process_madrid_month(month, output_path):\n",
    "    locations_by_id_and_month = get_locations_by_id_and_month()\n",
    "    month_df = pd.DataFrame(generate_data_by_counter(month, locations_by_id_and_month))\n",
    "    month_df.to_parquet(output_path / 'all' / f'counters_{month}.parquet', compression=\"snappy\")\n",
    "    return month_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c668f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: uncomment if processing data\n",
    "# process_madrid_month('2021-06', MADRID_PATH)\n",
    "# process_madrid_month('2021-07', MADRID_PATH)\n",
    "# process_madrid_month('2021-08', MADRID_PATH)\n",
    "# process_madrid_month('2021-09', MADRID_PATH)\n",
    "# process_madrid_month('2021-10', MADRID_PATH)\n",
    "# process_madrid_month('2021-11', MADRID_PATH)\n",
    "# process_madrid_month('2021-12', MADRID_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ff3a09ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregated 124525 counter volume lists\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[372, 360, 228, 240, 120, 72, 144, 132, 132, 7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1002</td>\n",
       "      <td>40.408030</td>\n",
       "      <td>-3.743760</td>\n",
       "      <td>66.768303</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[432, 372, 372, 228, 72, 12, 144, 132, 84, 60,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1003</td>\n",
       "      <td>40.406824</td>\n",
       "      <td>-3.746834</td>\n",
       "      <td>67.775190</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[492, 528, 456, 360, 168, 132, 252, 204, 72, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1006</td>\n",
       "      <td>40.411894</td>\n",
       "      <td>-3.736324</td>\n",
       "      <td>69.955706</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[396, 372, 288, 228, 96, 108, 156, 108, 180, 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1009</td>\n",
       "      <td>40.416234</td>\n",
       "      <td>-3.724909</td>\n",
       "      <td>68.506837</td>\n",
       "      <td>2021-06-01</td>\n",
       "      <td>[252, 264, 60, 132, 240, 240, 72, 60, 12, 144,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124520</th>\n",
       "      <td>10809</td>\n",
       "      <td>40.467826</td>\n",
       "      <td>-3.690572</td>\n",
       "      <td>221.955517</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>[40, 60, 0, 120, 17, -1, -1, -1, -1, -1, -1, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124521</th>\n",
       "      <td>10810</td>\n",
       "      <td>40.402183</td>\n",
       "      <td>-3.674159</td>\n",
       "      <td>223.257682</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>[37, 25, 12, 31, 33, 26, 12, 7, 7, 24, 14, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124522</th>\n",
       "      <td>10812</td>\n",
       "      <td>40.425322</td>\n",
       "      <td>-3.686722</td>\n",
       "      <td>272.307127</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>[162, 190, 210, 161, 144, 121, 65, 103, 58, 64...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124523</th>\n",
       "      <td>10813</td>\n",
       "      <td>40.472008</td>\n",
       "      <td>-3.700839</td>\n",
       "      <td>67.695344</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>[74, 85, 82, 53, 55, 67, 34, 49, -1, 37, -1, 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124524</th>\n",
       "      <td>10814</td>\n",
       "      <td>40.399327</td>\n",
       "      <td>-3.687896</td>\n",
       "      <td>93.335224</td>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>[165, 117, 144, 97, 93, 97, 86, 76, 40, 40, 26...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124525 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id        lat       lon     heading         day  \\\n",
       "0        1001  40.409729 -3.740786   62.428189  2021-06-01   \n",
       "1        1002  40.408030 -3.743760   66.768303  2021-06-01   \n",
       "2        1003  40.406824 -3.746834   67.775190  2021-06-01   \n",
       "3        1006  40.411894 -3.736324   69.955706  2021-06-01   \n",
       "4        1009  40.416234 -3.724909   68.506837  2021-06-01   \n",
       "...       ...        ...       ...         ...         ...   \n",
       "124520  10809  40.467826 -3.690572  221.955517  2021-06-30   \n",
       "124521  10810  40.402183 -3.674159  223.257682  2021-06-30   \n",
       "124522  10812  40.425322 -3.686722  272.307127  2021-06-30   \n",
       "124523  10813  40.472008 -3.700839   67.695344  2021-06-30   \n",
       "124524  10814  40.399327 -3.687896   93.335224  2021-06-30   \n",
       "\n",
       "                                                   volume  \n",
       "0       [372, 360, 228, 240, 120, 72, 144, 132, 132, 7...  \n",
       "1       [432, 372, 372, 228, 72, 12, 144, 132, 84, 60,...  \n",
       "2       [492, 528, 456, 360, 168, 132, 252, 204, 72, 6...  \n",
       "3       [396, 372, 288, 228, 96, 108, 156, 108, 180, 1...  \n",
       "4       [252, 264, 60, 132, 240, 240, 72, 60, 12, 144,...  \n",
       "...                                                   ...  \n",
       "124520  [40, 60, 0, 120, 17, -1, -1, -1, -1, -1, -1, -...  \n",
       "124521  [37, 25, 12, 31, 33, 26, 12, 7, 7, 24, 14, 8, ...  \n",
       "124522  [162, 190, 210, 161, 144, 121, 65, 103, 58, 64...  \n",
       "124523  [74, 85, 82, 53, 55, 67, 34, 49, -1, 37, -1, 6...  \n",
       "124524  [165, 117, 144, 97, 93, 97, 86, 76, 40, 40, 26...  \n",
       "\n",
       "[124525 rows x 6 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_madrid(month):\n",
    "    df = pd.read_parquet(MADRID_PATH / 'all' / f'counters_{month}.parquet')\n",
    "    df['t'] = [t_from_time_bin(tb, False) for tb in df['time_bin']]\n",
    "    df['day'] = [day_from_time_bin(tb, False) for tb in df['time_bin']]\n",
    "    df = df[df['day'].str.startswith(month)]\n",
    "    df = process_volume_normalization(df)\n",
    "    df = df[['id', 'lat', 'lon', 'heading', 'day', 'volume']]\n",
    "    df.to_parquet(MADRID_PATH / f'counters_normalized_{month}.parquet', compression=\"snappy\")\n",
    "    return df\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "normalize_madrid('2021-06')\n",
    "# normalize_madrid('2021-07')\n",
    "# normalize_madrid('2021-08')\n",
    "# normalize_madrid('2021-09')\n",
    "# normalize_madrid('2021-10')\n",
    "# normalize_madrid('2021-11')\n",
    "# normalize_madrid('2021-12')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c8e4ce88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>time_bin</th>\n",
       "      <th>type</th>\n",
       "      <th>volume</th>\n",
       "      <th>occupation</th>\n",
       "      <th>congestion_level</th>\n",
       "      <th>speed_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01 00:00</td>\n",
       "      <td>M30</td>\n",
       "      <td>372</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01 00:15</td>\n",
       "      <td>M30</td>\n",
       "      <td>360</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01 00:30</td>\n",
       "      <td>M30</td>\n",
       "      <td>228</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01 00:45</td>\n",
       "      <td>M30</td>\n",
       "      <td>240</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>40.409729</td>\n",
       "      <td>-3.740786</td>\n",
       "      <td>62.428189</td>\n",
       "      <td>2021-06-01 01:00</td>\n",
       "      <td>M30</td>\n",
       "      <td>120</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228462</th>\n",
       "      <td>10662</td>\n",
       "      <td>40.419298</td>\n",
       "      <td>-3.658963</td>\n",
       "      <td>199.072758</td>\n",
       "      <td>2021-12-31 22:45</td>\n",
       "      <td>M30</td>\n",
       "      <td>80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228463</th>\n",
       "      <td>10662</td>\n",
       "      <td>40.419298</td>\n",
       "      <td>-3.658963</td>\n",
       "      <td>199.072758</td>\n",
       "      <td>2021-12-31 23:00</td>\n",
       "      <td>M30</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228464</th>\n",
       "      <td>10662</td>\n",
       "      <td>40.419298</td>\n",
       "      <td>-3.658963</td>\n",
       "      <td>199.072758</td>\n",
       "      <td>2021-12-31 23:15</td>\n",
       "      <td>M30</td>\n",
       "      <td>67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228465</th>\n",
       "      <td>10662</td>\n",
       "      <td>40.419298</td>\n",
       "      <td>-3.658963</td>\n",
       "      <td>199.072758</td>\n",
       "      <td>2021-12-31 23:30</td>\n",
       "      <td>M30</td>\n",
       "      <td>48</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1228466</th>\n",
       "      <td>10662</td>\n",
       "      <td>40.419298</td>\n",
       "      <td>-3.658963</td>\n",
       "      <td>199.072758</td>\n",
       "      <td>2021-12-31 23:45</td>\n",
       "      <td>M30</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8514860 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id        lat       lon     heading          time_bin type  \\\n",
       "0         1001  40.409729 -3.740786   62.428189  2021-06-01 00:00  M30   \n",
       "1         1001  40.409729 -3.740786   62.428189  2021-06-01 00:15  M30   \n",
       "2         1001  40.409729 -3.740786   62.428189  2021-06-01 00:30  M30   \n",
       "3         1001  40.409729 -3.740786   62.428189  2021-06-01 00:45  M30   \n",
       "4         1001  40.409729 -3.740786   62.428189  2021-06-01 01:00  M30   \n",
       "...        ...        ...       ...         ...               ...  ...   \n",
       "1228462  10662  40.419298 -3.658963  199.072758  2021-12-31 22:45  M30   \n",
       "1228463  10662  40.419298 -3.658963  199.072758  2021-12-31 23:00  M30   \n",
       "1228464  10662  40.419298 -3.658963  199.072758  2021-12-31 23:15  M30   \n",
       "1228465  10662  40.419298 -3.658963  199.072758  2021-12-31 23:30  M30   \n",
       "1228466  10662  40.419298 -3.658963  199.072758  2021-12-31 23:45  M30   \n",
       "\n",
       "         volume  occupation  congestion_level  speed_avg  \n",
       "0           372         1.0               0.0       51.0  \n",
       "1           360         1.0               0.0       63.0  \n",
       "2           228         1.0               0.0       58.0  \n",
       "3           240         1.0               0.0       60.0  \n",
       "4           120         NaN               0.0       60.0  \n",
       "...         ...         ...               ...        ...  \n",
       "1228462      80         0.0               5.0       73.0  \n",
       "1228463      48         0.0               3.0       51.0  \n",
       "1228464      67         0.0               5.0       50.0  \n",
       "1228465      48         0.0               2.0       62.0  \n",
       "1228466      32         0.0               2.0       41.0  \n",
       "\n",
       "[8514860 rows x 10 columns]"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: uncomment if processing data\n",
    "m30_madrid_df = pd.concat([\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-06.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-07.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-08.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-09.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-10.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-11.parquet', filters=[('type','=','M30')]),\n",
    "    pd.read_parquet(MADRID_PATH / 'all' / 'counters_2021-12.parquet', filters=[('type','=','M30')])\n",
    "])\n",
    "m30_madrid_df.to_parquet(MADRID_PATH / 'm30_madrid_202106-202112.parquet', compression=\"snappy\")\n",
    "m30_madrid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdf81e2",
   "metadata": {},
   "source": [
    "# Melbourne (additional data, not used for MeTS-10 validations)\n",
    "\n",
    "The raw files are getting downloaded from https://discover.data.vic.gov.au/dataset/traffic-signal-volume-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d64125b",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIC_OPENDATA = 'https://vicroadsopendatastorehouse.vicroads.vic.gov.au/opendata'\n",
    "\n",
    "def scrape_vicroads():\n",
    "    for date in pd.date_range('2020-05-01', '2021-01-31', freq='M'):\n",
    "        month = date.strftime(\"%Y%m\")\n",
    "        zip_file = MELBOURNE_PATH / 'downloads' / f'VSDATA_{month}.zip'\n",
    "        if os.path.exists(zip_file):\n",
    "            continue\n",
    "        zip_file.parent.mkdir(exist_ok=True, parents=True)\n",
    "        url = f'{VIC_OPENDATA}/Traffic_Measurement/SCATS/VSDATA/VSDATA_{month}.zip'\n",
    "        print(f'Downloading {url}')\n",
    "        r = requests.get(url, allow_redirects=True)\n",
    "        open(zip_file, 'wb').write(r.content)\n",
    "        \n",
    "scrape_vicroads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4bc02528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2342645"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Download https://discover.data.vic.gov.au/dataset/traffic-lights1 as geojson\n",
    "locations_url = (\n",
    "    'https://vicroadsopendata-vicroadsmaps.opendata.arcgis.com/datasets/'\n",
    "    '1f3cb954526b471596dbffa30e56bb32_0.geojson?outSR=%7B%22latestWkid%22%3A3111%2C%22wkid%22%3A102171%7D'\n",
    ")\n",
    "r = requests.get(locations_url, allow_redirects=True)\n",
    "open(MELBOURNE_PATH / 'downloads' / 'Traffic_Lights.geojson', 'wb').write(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aed5a37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 4852 site locations\n"
     ]
    }
   ],
   "source": [
    "MELBOURNE_BBOX = [-3810600, -3761100, 14475700, 14519300]\n",
    "\n",
    "melbourne_locations = geopandas.read_file(MELBOURNE_PATH / 'downloads' / 'Traffic_Lights.geojson')\n",
    "print(f'Loaded {len(melbourne_locations)} site locations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02ee079d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 4229 unique locations\n"
     ]
    }
   ],
   "source": [
    "def read_vsdata_site_ids(zip_file, locations_df):\n",
    "    all_site_ids = set()\n",
    "    cfa = zipfile.ZipFile(zip_file, 'r')\n",
    "    for csv_file in cfa.namelist():\n",
    "        f = cfa.open(csv_file, 'r')\n",
    "        csvreader = csv.reader(TextIOWrapper(f, 'utf-8'), delimiter=',')\n",
    "        header = next(csvreader)\n",
    "        for row in csvreader:\n",
    "            try:\n",
    "                nb_scats_site = int(row[0])\n",
    "                all_site_ids.add(nb_scats_site)\n",
    "            except Exception:\n",
    "                continue\n",
    "    print(f'Read {len(all_site_ids)} unique locations')\n",
    "    return list(all_site_ids)\n",
    "\n",
    "melbourne_site_ids = read_vsdata_site_ids(MELBOURNE_PATH / 'downloads' / 'VSDATA_202006.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a3093471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBJECTID</th>\n",
       "      <th>TLIGHTS_</th>\n",
       "      <th>TLIGHTS_ID</th>\n",
       "      <th>SITE_NO</th>\n",
       "      <th>SITE_NAME</th>\n",
       "      <th>SITE_TYPE</th>\n",
       "      <th>DIRECTORY</th>\n",
       "      <th>DIR_REF</th>\n",
       "      <th>D_ADDED</th>\n",
       "      <th>D_TOWNS</th>\n",
       "      <th>D_EDITED</th>\n",
       "      <th>D_REMOVED</th>\n",
       "      <th>LINK_MODE</th>\n",
       "      <th>STATUS</th>\n",
       "      <th>COMMENTS</th>\n",
       "      <th>MULTI</th>\n",
       "      <th>UFI</th>\n",
       "      <th>ARC_UFI</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>48442</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>100</td>\n",
       "      <td>BURWOOD HWY/LIVINGSTONE</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.18105 -37.85642)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4133</th>\n",
       "      <td>49175</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>101</td>\n",
       "      <td>WELLS/CHELSEA HEIGHTS HOTEL</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>MICROCEL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.13197 -38.02945)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>45429</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>111</td>\n",
       "      <td>MAROONDAH HWY/METROPOLITAN</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>Bluetooth</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.16846 -37.81827)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2964</th>\n",
       "      <td>48006</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>112</td>\n",
       "      <td>MAROONDAH/STATION</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.19231 -37.81656)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2965</th>\n",
       "      <td>48007</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>113</td>\n",
       "      <td>MAROONDAH/STATION/WILLIAMS</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.15037 -37.81741)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>48551</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5297</td>\n",
       "      <td>POINT COOK NR CATHERINE (NORTH)</td>\n",
       "      <td>POS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (144.75773 -37.87780)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3615</th>\n",
       "      <td>48657</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5298</td>\n",
       "      <td>POINT COOK NR CATHERINE (SOUTH)</td>\n",
       "      <td>POS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (144.75747 -37.87917)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4531</th>\n",
       "      <td>49573</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>5329</td>\n",
       "      <td>RIVERSDALE ROAD EAST OF WESTBOURNE GROVE</td>\n",
       "      <td>POS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>RAIL LNK,UPS</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (145.06925 -37.83280)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>660</th>\n",
       "      <td>45702</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7047</td>\n",
       "      <td>SWALLOW/LIGHT RAIL CROSSING</td>\n",
       "      <td>INT</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td>TRAM PRI</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (144.93628 -37.83769)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>45661</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>7538</td>\n",
       "      <td>MILLERS BTW KOROROIT CK &amp; ROSS</td>\n",
       "      <td>POS</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>OPERATIONAL</td>\n",
       "      <td></td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>POINT (144.84533 -37.84846)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2597 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      OBJECTID TLIGHTS_ TLIGHTS_ID  SITE_NO  \\\n",
       "3400     48442     None       None      100   \n",
       "4133     49175     None       None      101   \n",
       "387      45429     None       None      111   \n",
       "2964     48006     None       None      112   \n",
       "2965     48007     None       None      113   \n",
       "...        ...      ...        ...      ...   \n",
       "3509     48551     None       None     5297   \n",
       "3615     48657     None       None     5298   \n",
       "4531     49573     None       None     5329   \n",
       "660      45702     None       None     7047   \n",
       "619      45661     None       None     7538   \n",
       "\n",
       "                                     SITE_NAME SITE_TYPE DIRECTORY DIR_REF  \\\n",
       "3400                   BURWOOD HWY/LIVINGSTONE       INT                     \n",
       "4133               WELLS/CHELSEA HEIGHTS HOTEL       INT                     \n",
       "387                 MAROONDAH HWY/METROPOLITAN       INT                     \n",
       "2964                         MAROONDAH/STATION       INT                     \n",
       "2965                MAROONDAH/STATION/WILLIAMS       INT                     \n",
       "...                                        ...       ...       ...     ...   \n",
       "3509           POINT COOK NR CATHERINE (NORTH)       POS                     \n",
       "3615           POINT COOK NR CATHERINE (SOUTH)       POS                     \n",
       "4531  RIVERSDALE ROAD EAST OF WESTBOURNE GROVE       POS                     \n",
       "660                SWALLOW/LIGHT RAIL CROSSING       INT                     \n",
       "619             MILLERS BTW KOROROIT CK & ROSS       POS                     \n",
       "\n",
       "     D_ADDED D_TOWNS D_EDITED D_REMOVED LINK_MODE       STATUS      COMMENTS  \\\n",
       "3400    None    None     None      None      None  OPERATIONAL                 \n",
       "4133    None    None     None      None      None  OPERATIONAL      MICROCEL   \n",
       "387     None    None     None      None      None  OPERATIONAL     Bluetooth   \n",
       "2964    None    None     None      None      None  OPERATIONAL                 \n",
       "2965    None    None     None      None      None  OPERATIONAL                 \n",
       "...      ...     ...      ...       ...       ...          ...           ...   \n",
       "3509    None    None     None      None      None  OPERATIONAL                 \n",
       "3615    None    None     None      None      None  OPERATIONAL                 \n",
       "4531    None    None     None      None      None  OPERATIONAL  RAIL LNK,UPS   \n",
       "660     None    None     None      None      None  OPERATIONAL      TRAM PRI   \n",
       "619     None    None     None      None      None  OPERATIONAL                 \n",
       "\n",
       "     MULTI   UFI ARC_UFI                     geometry  \n",
       "3400  None  None    None  POINT (145.18105 -37.85642)  \n",
       "4133  None  None    None  POINT (145.13197 -38.02945)  \n",
       "387   None  None    None  POINT (145.16846 -37.81827)  \n",
       "2964  None  None    None  POINT (145.19231 -37.81656)  \n",
       "2965  None  None    None  POINT (145.15037 -37.81741)  \n",
       "...    ...   ...     ...                          ...  \n",
       "3509  None  None    None  POINT (144.75773 -37.87780)  \n",
       "3615  None  None    None  POINT (144.75747 -37.87917)  \n",
       "4531  None  None    None  POINT (145.06925 -37.83280)  \n",
       "660   None  None    None  POINT (144.93628 -37.83769)  \n",
       "619   None  None    None  POINT (144.84533 -37.84846)  \n",
       "\n",
       "[2597 rows x 19 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filter only the used counter locations in the bounding box\n",
    "melbourne_locations = melbourne_locations[melbourne_locations['SITE_NO'].isin(melbourne_site_ids)]\n",
    "ymin, ymax, xmin, xmax = tuple([v/100000 for v in MELBOURNE_BBOX])\n",
    "melbourne_locations = melbourne_locations.cx[xmin:xmax, ymin:ymax]\n",
    "\n",
    "melbourne_locations = melbourne_locations.sort_values(by='SITE_NO')\n",
    "melbourne_locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "afb99580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the counter locations to geojson\n",
    "get_gdf(melbourne_locations, 'SITE_NO').to_file(MELBOURNE_PATH / 'counter_locations.geojson', driver=\"GeoJSON\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2f87f3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-01: 20000\n",
      "2020-06-02: 40000\n",
      "2020-06-04: 60000\n",
      "2020-06-04: 80000\n",
      "2020-06-05: 100000\n",
      "2020-06-06: 120000\n",
      "2020-06-07: 140000\n",
      "2020-06-07: 160000\n",
      "2020-06-08: 180000\n",
      "2020-06-09: 200000\n",
      "2020-06-10: 220000\n",
      "2020-06-11: 240000\n",
      "2020-06-11: 260000\n",
      "2020-06-12: 280000\n",
      "2020-06-13: 300000\n",
      "2020-06-14: 320000\n",
      "2020-06-14: 340000\n",
      "2020-06-15: 360000\n",
      "2020-06-16: 380000\n",
      "2020-06-17: 400000\n",
      "2020-06-17: 420000\n",
      "2020-06-18: 440000\n",
      "2020-06-19: 460000\n",
      "2020-06-20: 480000\n",
      "2020-06-21: 500000\n",
      "2020-06-21: 520000\n",
      "2020-06-22: 540000\n",
      "2020-06-23: 560000\n",
      "2020-06-24: 580000\n",
      "2020-06-24: 600000\n",
      "2020-06-25: 620000\n",
      "2020-06-26: 640000\n",
      "2020-06-27: 660000\n",
      "2020-06-27: 680000\n",
      "2020-06-28: 700000\n",
      "2020-06-29: 720000\n",
      "2020-06-30: 740000\n",
      "2020-06-30: 760000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sub_id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>-37.818267</td>\n",
       "      <td>145.168460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[3, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>-37.818267</td>\n",
       "      <td>145.168460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[7, 7, 4, 4, 4, 4, 3, 3, 3, 3, 2, 1, 0, 2, 4, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>111</td>\n",
       "      <td>3</td>\n",
       "      <td>-37.818267</td>\n",
       "      <td>145.168460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[1, 1, 1, 2, 3, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111</td>\n",
       "      <td>4</td>\n",
       "      <td>-37.818267</td>\n",
       "      <td>145.168460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>111</td>\n",
       "      <td>5</td>\n",
       "      <td>-37.818267</td>\n",
       "      <td>145.168460</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[2, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762994</th>\n",
       "      <td>4705</td>\n",
       "      <td>20</td>\n",
       "      <td>-37.913666</td>\n",
       "      <td>145.132195</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762995</th>\n",
       "      <td>4705</td>\n",
       "      <td>21</td>\n",
       "      <td>-37.913666</td>\n",
       "      <td>145.132195</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762996</th>\n",
       "      <td>4705</td>\n",
       "      <td>22</td>\n",
       "      <td>-37.913666</td>\n",
       "      <td>145.132195</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762997</th>\n",
       "      <td>4705</td>\n",
       "      <td>23</td>\n",
       "      <td>-37.913666</td>\n",
       "      <td>145.132195</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762998</th>\n",
       "      <td>4705</td>\n",
       "      <td>24</td>\n",
       "      <td>-37.913666</td>\n",
       "      <td>145.132195</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>762999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sub_id        lat         lon  heading         day  \\\n",
       "0        111       1 -37.818267  145.168460       -1  2020-06-01   \n",
       "1        111       2 -37.818267  145.168460       -1  2020-06-01   \n",
       "2        111       3 -37.818267  145.168460       -1  2020-06-01   \n",
       "3        111       4 -37.818267  145.168460       -1  2020-06-01   \n",
       "4        111       5 -37.818267  145.168460       -1  2020-06-01   \n",
       "...      ...     ...        ...         ...      ...         ...   \n",
       "762994  4705      20 -37.913666  145.132195       -1  2020-06-30   \n",
       "762995  4705      21 -37.913666  145.132195       -1  2020-06-30   \n",
       "762996  4705      22 -37.913666  145.132195       -1  2020-06-30   \n",
       "762997  4705      23 -37.913666  145.132195       -1  2020-06-30   \n",
       "762998  4705      24 -37.913666  145.132195       -1  2020-06-30   \n",
       "\n",
       "                                                   volume  \n",
       "0       [3, 0, 1, 0, 1, 0, 1, 1, 0, 0, 2, 1, 0, 2, 0, ...  \n",
       "1       [7, 7, 4, 4, 4, 4, 3, 3, 3, 3, 2, 1, 0, 2, 4, ...  \n",
       "2       [1, 1, 1, 2, 3, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, ...  \n",
       "3       [0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, ...  \n",
       "4       [2, 1, 2, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "...                                                   ...  \n",
       "762994  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "762995  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "762996  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "762997  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "762998  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[762999 rows x 7 columns]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def process_vsdata(year, month, locations_df):\n",
    "    unique_sites = set(locations_df['SITE_NO'].values)\n",
    "    zip_file = MELBOURNE_PATH / 'downloads' / f'VSDATA_{year:04d}{month:02d}.zip'\n",
    "    count = 0\n",
    "    data = []\n",
    "    cfa = zipfile.ZipFile(zip_file, 'r')\n",
    "    for csv_file in cfa.namelist():\n",
    "        day_bin = csv_file[7:15]\n",
    "        day_bin = f'{day_bin[:4]}-{day_bin[4:6]}-{day_bin[6:]}'\n",
    "        f = cfa.open(csv_file, 'r')\n",
    "        csvreader = csv.reader(TextIOWrapper(f, 'utf-8'), delimiter=',')\n",
    "        header = next(csvreader)\n",
    "        for row in csvreader:\n",
    "            try:\n",
    "                nb_scats_site = int(row[0])\n",
    "                nb_detector = int(row[2])\n",
    "                volumes = [int(row[i]) for i in range(3,99)]\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not np.any(np.array(volumes)):\n",
    "                continue\n",
    "            if nb_scats_site not in unique_sites:\n",
    "                continue\n",
    "            site_df = locations_df[locations_df['SITE_NO'] == nb_scats_site]\n",
    "            point = site_df['geometry'].iloc[0]\n",
    "            lat = point.y\n",
    "            lon = point.x\n",
    "            volumes = [max(v, 0) for v in volumes]\n",
    "            heading = -1\n",
    "            data.append({\n",
    "                'id': nb_scats_site, 'sub_id': nb_detector, 'lat': lat, 'lon': lon, 'heading': heading, \n",
    "                'day': day_bin, 'volume': volumes\n",
    "            })\n",
    "            count += 1\n",
    "            if count % 20000 == 0:\n",
    "                print(f'{day_bin}: {count}')\n",
    "    df = pd.DataFrame.from_records(data)\n",
    "    df.to_parquet(MELBOURNE_PATH / f'counters_{year:04d}-{month:02d}.parquet', compression=\"snappy\")\n",
    "    return df\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "process_vsdata(2020, 6, melbourne_locations)\n",
    "# process_vsdata(2020, 7, melbourne_locations)\n",
    "# process_vsdata(2020, 8, melbourne_locations)\n",
    "# process_vsdata(2020, 9, melbourne_locations)\n",
    "# process_vsdata(2020, 10, melbourne_locations)\n",
    "# process_vsdata(2020, 11, melbourne_locations)\n",
    "# process_vsdata(2020, 12, melbourne_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "a92ac8b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>heading</th>\n",
       "      <th>day</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "      <td>-37.856420</td>\n",
       "      <td>145.181054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>[27, 23, 22, 15, 17, 16, 13, 15, 16, 13, 6, 12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100</td>\n",
       "      <td>-37.856420</td>\n",
       "      <td>145.181054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-02</td>\n",
       "      <td>[38, 26, 23, 32, 19, 12, 9, 10, 15, 6, 15, 8, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>-37.856420</td>\n",
       "      <td>145.181054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-04</td>\n",
       "      <td>[31, 37, 33, 16, 18, 18, 13, 16, 16, 11, 7, 11...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100</td>\n",
       "      <td>-37.856420</td>\n",
       "      <td>145.181054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>[30, 47, 21, 23, 24, 13, 18, 8, 16, 14, 7, 6, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100</td>\n",
       "      <td>-37.856420</td>\n",
       "      <td>145.181054</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-06</td>\n",
       "      <td>[60, 66, 49, 38, 38, 34, 31, 26, 15, 18, 21, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73719</th>\n",
       "      <td>7047</td>\n",
       "      <td>-37.837689</td>\n",
       "      <td>144.936283</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-26</td>\n",
       "      <td>[4, 11, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73720</th>\n",
       "      <td>7047</td>\n",
       "      <td>-37.837689</td>\n",
       "      <td>144.936283</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-27</td>\n",
       "      <td>[4, 6, 8, 2, 1, 14, 9, 5, 3, 3, 3, 3, 3, 3, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73721</th>\n",
       "      <td>7047</td>\n",
       "      <td>-37.837689</td>\n",
       "      <td>144.936283</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-28</td>\n",
       "      <td>[6, 4, 6, 4, 7, 4, 3, 4, 12, 0, 3, 3, 6, 0, 5,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73722</th>\n",
       "      <td>7047</td>\n",
       "      <td>-37.837689</td>\n",
       "      <td>144.936283</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-29</td>\n",
       "      <td>[5, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73723</th>\n",
       "      <td>7047</td>\n",
       "      <td>-37.837689</td>\n",
       "      <td>144.936283</td>\n",
       "      <td>-1</td>\n",
       "      <td>2020-06-30</td>\n",
       "      <td>[3, 9, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>73724 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id        lat         lon  heading         day  \\\n",
       "0       100 -37.856420  145.181054       -1  2020-06-01   \n",
       "1       100 -37.856420  145.181054       -1  2020-06-02   \n",
       "2       100 -37.856420  145.181054       -1  2020-06-04   \n",
       "3       100 -37.856420  145.181054       -1  2020-06-05   \n",
       "4       100 -37.856420  145.181054       -1  2020-06-06   \n",
       "...     ...        ...         ...      ...         ...   \n",
       "73719  7047 -37.837689  144.936283       -1  2020-06-26   \n",
       "73720  7047 -37.837689  144.936283       -1  2020-06-27   \n",
       "73721  7047 -37.837689  144.936283       -1  2020-06-28   \n",
       "73722  7047 -37.837689  144.936283       -1  2020-06-29   \n",
       "73723  7047 -37.837689  144.936283       -1  2020-06-30   \n",
       "\n",
       "                                                  volume  \n",
       "0      [27, 23, 22, 15, 17, 16, 13, 15, 16, 13, 6, 12...  \n",
       "1      [38, 26, 23, 32, 19, 12, 9, 10, 15, 6, 15, 8, ...  \n",
       "2      [31, 37, 33, 16, 18, 18, 13, 16, 16, 11, 7, 11...  \n",
       "3      [30, 47, 21, 23, 24, 13, 18, 8, 16, 14, 7, 6, ...  \n",
       "4      [60, 66, 49, 38, 38, 34, 31, 26, 15, 18, 21, 2...  \n",
       "...                                                  ...  \n",
       "73719  [4, 11, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n",
       "73720  [4, 6, 8, 2, 1, 14, 9, 5, 3, 3, 3, 3, 3, 3, 5,...  \n",
       "73721  [6, 4, 6, 4, 7, 4, 3, 4, 12, 0, 3, 3, 6, 0, 5,...  \n",
       "73722  [5, 6, 0, 0, 0, 0, 0, 0, 6, 0, 0, 0, 0, 0, 1, ...  \n",
       "73723  [3, 9, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, ...  \n",
       "\n",
       "[73724 rows x 6 columns]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize_volumes_melbourne(x):\n",
    "    volumes = x.volume\n",
    "    sub_ids = x.sub_id\n",
    "    assert(len(volumes) == len(sub_ids))\n",
    "    res_volumes = []\n",
    "    for v in volumes:\n",
    "        if len(res_volumes) == 0:\n",
    "            res_volumes = v\n",
    "        else:\n",
    "            res_volumes = np.add(res_volumes, v)\n",
    "    assert(len(res_volumes) == 96)\n",
    "    return pd.Series([res_volumes], index=['volume'])\n",
    "\n",
    "def normalize_melbourne(month):\n",
    "    df = pd.read_parquet(MELBOURNE_PATH / f'counters_{month}.parquet')\n",
    "    df = df.sort_values(['id','lat','lon','heading'], ascending=False).groupby(\n",
    "        ['id','lat','lon','heading', 'day']).agg({'volume':lambda x: list(x), 'sub_id':lambda x: list(x)})\n",
    "    df = df.apply(normalize_volumes_melbourne, axis=1, result_type='expand').reset_index()\n",
    "    df.to_parquet(MELBOURNE_PATH / f'counters_normalized_{month}.parquet', compression=\"snappy\")\n",
    "    return df\n",
    "\n",
    "# TODO: uncomment if processing data\n",
    "normalize_melbourne('2020-06')\n",
    "# normalize_melbourne('2020-07')\n",
    "# normalize_melbourne('2020-08')\n",
    "# normalize_melbourne('2020-09')\n",
    "# normalize_melbourne('2020-10')\n",
    "# normalize_melbourne('2020-11')\n",
    "# normalize_melbourne('2020-12')"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.5",
    "jupytext_version": "1.11.2"
   }
  },
  "kernelspec": {
   "display_name": "Python [conda env:t4c22]",
   "language": "python",
   "name": "conda-env-t4c22-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
